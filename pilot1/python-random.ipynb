{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#to do, i need to create a matrix of units x timebins x trials per recording per event... \n",
    "\n",
    "num_pc_for_decoding = 10\n",
    "\n",
    "neural_data_pca = [[{} for _ in range(len(neural_data[0]))] for _ in range(len(neural_data))]\n",
    "#nueral_data = neurons x timebins x TRIALS \n",
    "\n",
    "for n1 in range(len(neural_data)):\n",
    "    for n2 in range(len(neural_data[0])):\n",
    "        if not neural_data[n1][n2]:\n",
    "            continue\n",
    "\n",
    "        neural_data_pca[n1][n2] = {\"reward\": [], \"fear\": [], \"conflict\": [], \"habituation\": [], \"iti\": []}\n",
    "\n",
    "        for n3 in range(neural_data[n1][n2][\"reward\"].shape[2]:\n",
    "            reward_data = neural_data[n1][n2][\"reward\"][:, :, n3]\n",
    "            selected_neurons = np.where(np.all(neuron2animalidx == [n1, n2], axis=1))[0]\n",
    "            #so can only use neuron rows from mouse who did that trial\n",
    "            pca_coeff = coef[selected_neurons, :num_pc_for_decoding]\n",
    "            result = pca_coeff.T.dot(reward_data)\n",
    "            neural_data_pca[n1][n2][\"reward\"].append(result)\n",
    "\n",
    "        for n3 in range(neural_data[n1][n2][\"fear\"].shape[2]):\n",
    "            fear_data = neural_data[n1][n2][\"fear\"][:, :, n3]\n",
    "            selected_neurons = np.where(np.all(neuron2animalidx == [n1, n2], axis=1))[0]\n",
    "            pca_coeff = coef[selected_neurons, :num_pc_for_decoding]\n",
    "            result = pca_coeff.T.dot(fear_data)\n",
    "            neural_data_pca[n1][n2][\"fear\"].append(result)\n",
    "\n",
    "        for n3 in range(neural_data[n1][n2][\"conflict\"].shape[2]):\n",
    "            conflict_data = neural_data[n1][n2][\"conflict\"][:, :, n3]\n",
    "            selected_neurons = np.where(np.all(neuron2animalidx == [n1, n2], axis=1))[0]\n",
    "            pca_coeff = coef[selected_neurons, :num_pc_for_decoding]\n",
    "            result = pca_coeff.T.dot(conflict_data)\n",
    "            neural_data_pca[n1][n2][\"conflict\"].append(result)\n",
    "\n",
    "        habituation_data = neural_data[n1][n2][\"habituation\"]\n",
    "        selected_neurons = np.where(np.all(neuron2animalidx == [n1, n2], axis=1))[0]\n",
    "        pca_coeff = coef[selected_neurons, :num_pc_for_decoding]\n",
    "        result = pca_coeff.T.dot(habituation_data)\n",
    "        neural_data_pca[n1][n2][\"habituation\"] = result\n",
    "\n",
    "        for n3 in range(neural_data[n1][n2][\"iti\"].shape[2]):\n",
    "            iti_data = neural_data[n1][n2][\"iti\"][:, :, n3]\n",
    "            selected_neurons = np.where(np.all(neuron2animalidx == [n1, n2], axis=1))[0]\n",
    "            pca_coeff = coef[selected_neurons, :num_pc_for_decoding]\n",
    "            result = pca_coeff.T.dot(iti_data)\n",
    "            neural_data_pca[n1][n2][\"iti\"].append(result)\n",
    "\n",
    "#pca calc = W (pcs x neurons) x D (neurons x timebins)\n",
    "#PCA output = PCsx timebins\n",
    "#neural_data_pca = { event: list(pcs x timebins)}\n",
    "\n",
    "num_fold = 5\n",
    "num_shuffle = 5\n",
    "\n",
    "decode_trial_type_auc = [{} for _ in range(len(neural_data_pca[0]))]\n",
    "decode_idx2trial_type = {1: \"reward\", 2: \"fear\", 3: \"conflict\"}\n",
    "decode_idx = [1, 2, 3]\n",
    "# iterating through n1 which is the length of the first dimension of the neural_data_pca\n",
    "#potentially this is number of event types? or number of timebins \n",
    "for n1 in range(len(neural_data_pca[0])): #hmmm i dont actually n1 is \n",
    "    decode_trial_type_auc_local = {}\n",
    "    # this also seems like number of events, but i guess i subset of interest events \n",
    "    for n2 in decode_idx:\n",
    "    #this foor loop looks for 1: 2&3, or 2: 1&3, 3: 2&3\n",
    "        for n3 in [x for x in decode_idx if x != n2]:\n",
    "            data_temp_pos = []\n",
    "            data_temp_neg = []\n",
    "\n",
    "            for n4 in range(len(neural_data_pca)): # for for every trial?\n",
    "                data_temp_pos.append(neural_data_pca[n4][n1][decode_idx2trial_type[n2]])\n",
    "                data_temp_neg.append(neural_data_pca[n4][n1][decode_idx2trial_type[n3]])\n",
    "                #so creating temp lists for later of the two event types currently being iterated?\n",
    "                #n4 = timebins , and n1 = PCs?????\n",
    "\n",
    "            data_temp_pos = np.stack(data_temp_pos, axis=2)\n",
    "            data_temp_neg = np.stack(data_temp_neg, axis=2)\n",
    "             # i think this is just turning a list into a multi dimensional numpy array\n",
    "\n",
    "            num_trial_pos = data_temp_pos.shape[2]\n",
    "            num_trial_neg = data_temp_neg.shape[2] # is a constant that reflects.... something\n",
    "\n",
    "            data_temp_pos = data_temp_pos[:, :, np.random.permutation(num_trial_pos)] # basically shuffling the order of trials\n",
    "            data_temp_neg = data_temp_neg[:, :, np.random.permutation(num_trial_neg)] # so that the model is not trained on conescutive trials \n",
    "            # so that the test set is not from one animal or one session\n",
    "\n",
    "            auc_glm = np.zeros((num_fold, T)) # i do not know what T is - possibly it is also timebins? \n",
    "\n",
    "            auc_rf = np.zeros((num_fold, T)) # possibly it is total time bins? event no. X event length\n",
    "            auc_glm_shuffle = np.zeros((num_fold, T, num_shuffle))\n",
    "            auc_rf_shuffle = np.zeros((num_fold, T, num_shuffle))\n",
    "            # so this is setting empty arrays for the actual stuff below \n",
    "\n",
    "            for n4 in range(num_fold):\n",
    "                # concatenate data_temp_pos with data_temp_neg along third axis (aka event) \n",
    "                #but only take 1/num_fold of data for test \n",
    "                data_test = np.concatenate((data_temp_pos[:, :, n4 * num_trial_pos // num_fold:(n4 + 1) * num_trial_pos // num_fold],\n",
    "                                            data_temp_neg[:, :, n4 * num_trial_neg // num_fold:(n4 + 1) * num_trial_neg // num_fold]), axis=2)\n",
    "               # creating the labels for the test set such that pos = 1 and neg trials = 0\n",
    "               # result is a 1d numpy array such as: 111100000000000\n",
    "                label_test = np.concatenate((np.ones((n4 + 1) * num_trial_pos // num_fold - n4 * num_trial_pos // num_fold),\n",
    "                                             np.zeros((n4 + 1) * num_trial_neg // num_fold - n4 * num_trial_neg // num_fold)))\n",
    "                data_train = np.concatenate((data_temp_pos[:, :, np.setdiff1d(np.arange(num_trial_pos), np.arange(n4 * num_trial_pos // num_fold, (n4 + 1) * num_trial_pos // num_fold))],\n",
    "                                             data_temp_neg[:, :, np.setdiff1d(np.arange(num_trial_neg), np.arange(n4 * num_trial_neg // num_fold, (n4 + 1) * num_trial_neg // num_fold))]), axis=2)\n",
    "                label_train = np.concatenate((np.ones(num_trial_pos - (n4 + 1) * num_trial_pos // num_fold + n4 * num_trial_pos // num_fold),\n",
    "                                             np.zeros(num_trial_neg - (n4 + 1) * num_trial_neg // num_fold + n4 * num_trial_neg // num_fold))\n",
    "                # check sizes of matrices before i even predict \n",
    "                # for testing set fold and shuffle number to 1\n",
    "                # STOP HERE FOR TESTING \n",
    "                for n5 in range(T):\n",
    "                    model_glm = LogisticRegression()\n",
    "                    #its possible i might beed to squeeze this like in matlab\n",
    "                    model_glm.fit(data_train[:, n5, :].T, label_train)\n",
    "                    pred_glm = model_glm.predict_proba(data_test[:, n5, :].T)\n",
    "                    auc_glm[n4, n5] = roc_auc_score(label_test, pred_glm[:, 1])\n",
    "\n",
    "                    model_rf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=0)\n",
    "                    model_rf.fit(data_train[:, n5, :].T, label_train)\n",
    "                    pred_rf = model_rf.predict_proba(data_test[:, n5, :].T)\n",
    "                    auc_rf[n4, n5] = roc_auc_score(label_test, pred_rf[:, 1])\n",
    "\n",
    "                for n5 in range(num_shuffle):\n",
    "                    label_train = shuffle(label_train)\n",
    "                    for n6 in range(T):\n",
    "                        model_glm = LogisticRegression()\n",
    "                        model_glm.fit(data_train[:, n6, :].T, label_train)\n",
    "                        pred_glm = model_glm.predict_proba(data_test[:, n6, :].T)\n",
    "                        auc_glm_shuffle[n4, n6, n5] = roc_auc_score(label_test, pred_glm[:, 1])\n",
    "\n",
    "                        model_rf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=0)\n",
    "                        model_rf.fit(data_train[:, n6, :].T, label_train)\n",
    "                        pred_rf = model_rf.predict_proba(data_test[:, n6, :].T)\n",
    "                        auc_rf_shuffle[n4, n6, n5] = roc_auc_score(label_test, pred_rf[:, 1])\n",
    "\n",
    "            decode_trial_type_auc_local[decode_idx2trial_type[n2] + \"_vs_\" + decode_idx2trial_type[n3] + \"_glm\"] = auc_glm\n",
    "            decode_trial_type_auc_local[decode_idx2trial_type[n2] + \"_vs_\" + decode_idx2trial_type[n3] + \"_rf\"] = auc_rf\n",
    "            decode_trial_type_auc_local[decode_idx2trial_type[n2] + \"_vs_\" + decode_idx2trial_type[n3] + \"_glm_shuffle\"] = auc_glm_shuffle\n",
    "            decode_trial_type_auc_local[decode_idx2trial_type[n2] + \"_vs_\" + decode_idx2trial_type[n3] + \"_rf_shuffle\"] = auc_rf_shuffle\n",
    "\n",
    "    decode_trial_type_auc[n1] = decode_trial_type_auc_local\n",
    "\n",
    "# Clear variables from the current namespace (you can manually remove unnecessary variables if needed)\n",
    "del num_fold, num_shuffle, decode_idx2trial_type, decode_idx, n1, decode_trial_type_auc_local, n2, n3, data_temp_pos, data_temp_neg\n",
    "del n4, num_trial_pos, num_trial_neg, auc_glm, auc_rf, auc_glm_shuffle, auc_rf_shuffle\n",
    "del data_test, label_test, data_train, label_train, n5, model_glm, pred_glm, auc_temp, auc_glm, model_rf, pred_rf, n6"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
