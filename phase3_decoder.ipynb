{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boris_extraction as boris\n",
    "import multirecording_spikeanalysis as spike\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import sem\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "def hex_2_rgb(hex_color): # Orange color\n",
    "    rgb_color = tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (1, 3, 5))\n",
    "    return rgb_color\n",
    "\n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):   \n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):   \n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unpickle_this' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m phase3_collection \u001b[38;5;241m=\u001b[39m \u001b[43munpickle_this\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphase3collection.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unpickle_this' is not defined"
     ]
    }
   ],
   "source": [
    "phase3_collection = unpickle_this('phase3collection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                               \n",
    "def get_indices(repeated_items_list):\n",
    "    \"\"\"\n",
    "    Takes in an indexed key or a list of repeated items, \n",
    "    creates a list of indices that correspond to each unique item.\n",
    "\n",
    "    Args (1):\n",
    "        repeated_items_list: list, list of repeated items\n",
    "\n",
    "    Returns:\n",
    "        item_indices: list of tuples, where the first element\n",
    "            is the first index of an item, and the second\n",
    "            element is the last index of that item\n",
    "    \"\"\"\n",
    "    is_first = True\n",
    "    item_indices = {}\n",
    "    for i in range(len(repeated_items_list)):\n",
    "        if is_first:\n",
    "            current_item = repeated_items_list[i]\n",
    "            start_index = 0\n",
    "            is_first = False\n",
    "        else:\n",
    "            if repeated_items_list[i] == current_item:\n",
    "                end_index = i\n",
    "                if i == (len(repeated_items_list)-1):\n",
    "                    item_indices[current_item] = [start_index, end_index]\n",
    "            else:\n",
    "                item_indices[current_item] = [start_index, end_index]\n",
    "                start_index = i\n",
    "                current_item = repeated_items_list[i]\n",
    "    return item_indices\n",
    "\n",
    "def __PCA_for_decoding__(equalize, pre_window, post_window, no_PCs, events, counter_events = None):\n",
    "        full_PCA_matrix, t_df, key, coefficients, explained_variance_ratios = phase3_analysis.PCA_matrix_generation(equalize, pre_window, post_window, events = events)\n",
    "        recordings = full_PCA_matrix.columns.to_list()\n",
    "        recording_list = np.unique(recordings)\n",
    "        coefficients = coefficients[:, :no_PCs]\n",
    "        recording_indices = get_indices(recordings)\n",
    "        decoder_data = {}\n",
    "        if counter_events is not None:\n",
    "            for event in counter_events:\n",
    "                if event not in events:\n",
    "                    events.append(event)\n",
    "        #decoder data dict: events for keys, values is a list of len(events)\n",
    "        #each element in the list is the transformed matrix\n",
    "        for recording in recording_list:\n",
    "            #iterate through recording\n",
    "            start = recording_indices[recording][0]\n",
    "            stop = recording_indices[recording][1]\n",
    "            #trim weight matrix for only those neurons in the current recording\n",
    "            subset_coeff = coefficients[start:stop+1, :]\n",
    "            recording_instance = phase3_analysis.ephyscollection.get_by_name(recording)\n",
    "            for event in events:\n",
    "                #grab all event firing rates for current event in current recording\n",
    "                event_firing_rates = phase3_analysis.__get_event_firing_rates__(recording_instance, event,\n",
    "                                                                equalize, pre_window, post_window)\n",
    "                for trial in range(len(event_firing_rates)):\n",
    "                    #iterate through each event\n",
    "                    trial_data = np.transpose(event_firing_rates[trial])\n",
    "                    #transpoe event firing rates from neurons x timebins to timebins x neurons\n",
    "                    transformed_trial = np.dot(trial_data, subset_coeff)\n",
    "                    #transform each trial with original weight matrix\n",
    "                    #T (timebins x pcs) = D (timebins x neurons). W (pcs x neurons) \n",
    "                    if event in decoder_data.keys():\n",
    "                        #append transformed matrix to decoder_data1 dict\n",
    "                        decoder_data[event].append(transformed_trial)\n",
    "                    else: \n",
    "                        decoder_data[event] = []\n",
    "                        decoder_data[event].append(transformed_trial)\n",
    "        return decoder_data\n",
    "\n",
    "\n",
    "\n",
    "def cross_trial_decoder(equalize, pre_window, post_window, num_fold, num_shuffle, no_PCs, same_event, event1, event2, plot = True):\n",
    "    decoder_data1 = __PCA_for_decoding__(equalize, pre_window, post_window, no_PCs, events = [same_event, event1], counter_events = [event2])\n",
    "    decoder_data2 = __PCA_for_decoding__(equalize, pre_window, post_window, no_PCs, events = [same_event, event2], counter_events = [event1])\n",
    "    ex_trial_matrix = decoder_data1[same_event][0]\n",
    "    T = ex_trial_matrix.shape[0]\n",
    "    auc = {}\n",
    "    diff_events = [event1, event2]\n",
    "    decoders = [decoder_data1, decoder_data2]\n",
    "    for i in [0,1]:  \n",
    "        data_neg_train = []\n",
    "        data_neg_test = []\n",
    "        data_pos = []\n",
    "        decoder_data = decoders[i]  \n",
    "        for trial in decoder_data[same_event]:\n",
    "            data_pos.append(trial)\n",
    "        for trial in decoder_data[diff_events[i]]:\n",
    "            data_neg_train.append(trial)\n",
    "        if i == 0:\n",
    "            for trial in decoder_data[diff_events[1]]:\n",
    "                data_neg_test.append(trial)\n",
    "        else:\n",
    "            for trial in decoder_data[diff_events[0]]:\n",
    "                data_neg_test.append(trial)\n",
    "        data_pos= np.stack(data_pos, axis=2)\n",
    "        data_neg_train = np.stack(data_neg_train, axis=2)\n",
    "        data_neg_test = np.stack(data_neg_test, axis=2)\n",
    "        num_pos = data_pos.shape[2]\n",
    "        num_neg_train = data_neg_train.shape[2]\n",
    "        num_neg_test = data_neg_test.shape[2]\n",
    "        data_pos = data_pos[:, :, np.random.permutation(num_pos)]\n",
    "        data_neg_train = data_neg_train[:, :, np.random.permutation(num_neg_train)]\n",
    "        data_neg_test = data_neg_test[:, :, np.random.permutation(num_neg_test)]\n",
    "        event = diff_events[i]\n",
    "        auc[event] = {'glm': [], 'rf': [], 'glm_shuffle': [], 'rf_shuffle': []}\n",
    "        for fold in range(num_fold):\n",
    "            auc_glm = []\n",
    "            auc_rf = []\n",
    "            auc_glm_shuffle = []\n",
    "            auc_rf_shuffle = []\n",
    "            pos_fold = num_pos // num_fold\n",
    "            neg_fold_train = num_neg_train // num_fold\n",
    "            neg_fold_test = num_neg_test // num_fold\n",
    "            data_test = np.concatenate((data_pos[:, :, fold * pos_fold:(fold + 1) * pos_fold],\n",
    "                                        data_neg_test[:, :, fold * neg_fold_test:(fold + 1) * neg_fold_test]), axis=2)\n",
    "            label_test = np.concatenate((np.ones((fold + 1) * pos_fold - fold * pos_fold),\n",
    "                                        np.zeros((fold + 1) * neg_fold_test - fold * neg_fold_test)))\n",
    "            data_train = np.concatenate((\n",
    "                data_pos[:, :, np.setdiff1d(np.arange(num_pos), \n",
    "                np.arange(fold * pos_fold, (fold + 1) * pos_fold))],\n",
    "                data_neg_train[:, :, np.setdiff1d(np.arange(num_neg_train), \n",
    "                np.arange(fold * neg_fold_train, (fold + 1) * neg_fold_train))]),\n",
    "                axis=2)\n",
    "            label_train = np.concatenate((np.ones(num_pos - (fold + 1) * pos_fold + fold * pos_fold),\n",
    "                                        np.zeros(num_neg_train - (fold + 1) * neg_fold_train + fold * neg_fold_train)))\n",
    "            for timebin in range(T):\n",
    "                model_glm = LogisticRegression(class_weight='balanced') \n",
    "                model_glm.fit(data_train[timebin, :, :].T, label_train)\n",
    "                pred_glm = model_glm.predict_proba(data_test[timebin, :, :].T)\n",
    "                auc_glm.append(roc_auc_score(label_test, pred_glm[:, 1]))\n",
    "                \n",
    "                model_rf = BaggingClassifier(estimator=DecisionTreeClassifier(class_weight = 'balanced'), n_estimators=50, random_state=0)\n",
    "                model_rf.fit(data_train[timebin, :, :].T, label_train)\n",
    "                pred_rf = model_rf.predict_proba(data_test[timebin, :, :].T)\n",
    "                auc_rf.append(roc_auc_score(label_test, pred_rf[:, 1]))\n",
    "            auc[event]['glm'].append(auc_glm)\n",
    "            auc[event]['rf'].append(auc_rf)\n",
    "            for shuffle in range(num_shuffle):\n",
    "                temp_glm_shuffle = []\n",
    "                temp_rf_shuffle = []\n",
    "                label_train = np.random.permutation(label_train)\n",
    "                for timebin in range(T):\n",
    "                    model_glm = LogisticRegression(class_weight='balanced')\n",
    "                    model_glm.fit(data_train[timebin, :, :].T, label_train)\n",
    "                    pred_glm = model_glm.predict_proba(data_test[timebin, :, :].T)\n",
    "                    temp_glm_shuffle.append(roc_auc_score(label_test, pred_glm[:, 1]))\n",
    "\n",
    "                    model_rf = BaggingClassifier(estimator=DecisionTreeClassifier(class_weight = 'balanced'), n_estimators=50, random_state=0)\n",
    "                    model_rf.fit(data_train[timebin, :, :].T, label_train)\n",
    "                    pred_rf = model_rf.predict_proba(data_test[timebin, :, :].T)\n",
    "                    temp_rf_shuffle.append(roc_auc_score(label_test, pred_rf[:, 1]))\n",
    "                auc_glm_shuffle.append(temp_glm_shuffle)\n",
    "                auc_rf_shuffle.append(temp_rf_shuffle)\n",
    "            auc[event]['glm_shuffle'].append(auc_glm_shuffle)\n",
    "            auc[event]['rf_shuffle'].append(auc_rf_shuffle)\n",
    "    if plot:\n",
    "        __plot_auc__(auc, equalize, pre_window)\n",
    "    return auc\n",
    "\n",
    "def trial_decoder_AvB_BvC(equalize, pre_window, post_window, num_fold, num_shuffle, no_PCs, training_events, test_events, plot = True):\n",
    "    #ugh fuck okay so this gonna take the 4/5 of positive training data, and make it the 1/5 neg data if two events are the same type\n",
    "    decoder_data = __PCA_for_decoding__(equalize, pre_window, post_window, no_PCs, events = training_events, counter_events = test_events)\n",
    "    ex_trial_matrix = decoder_data[training_events[0]][0]\n",
    "    T = ex_trial_matrix.shape[0]\n",
    "    all_events = list(set(training_events + test_events))\n",
    "    auc = {}  \n",
    "    data_A = []\n",
    "    data_B = []\n",
    "    data_C = []\n",
    "    i = 0\n",
    "    for event in all_events:\n",
    "        for trial in decoder_data[event]:\n",
    "            if i == 0: \n",
    "                data_A.append(trial)\n",
    "            if i == 1:\n",
    "                data_B.append(trial)\n",
    "            if i == 2:\n",
    "                data_C.append(trial)\n",
    "        i+=1\n",
    "    data_A= np.stack(data_A, axis=2)\n",
    "    data_B = np.stack(data_B, axis=2)\n",
    "    data_C = np.stack(data_C, axis=2)\n",
    "    num_A = data_A.shape[2]\n",
    "    num_B = data_B.shape[2]\n",
    "    num_C = data_C.shape[2]\n",
    "    data_A = data_A[:, :, np.random.permutation(num_A)]\n",
    "    data_B = data_B[:, :, np.random.permutation(num_B)]\n",
    "    data_C = data_C[:, :, np.random.permutation(num_C)]\n",
    "    auc = {'glm': [], 'rf': [], 'glm_shuffle': [], 'rf_shuffle': []}\n",
    "    for fold in range(num_fold):\n",
    "        auc_glm = []\n",
    "        auc_rf = []\n",
    "        auc_glm_shuffle = []\n",
    "        auc_rf_shuffle = []\n",
    "        A_fold = num_A // num_fold\n",
    "        B_fold = num_B // num_fold\n",
    "        C_fold = num_C // num_fold\n",
    "        data_test = np.concatenate((data_C[:, :, fold * C_fold:(fold + 1) * C_fold],\n",
    "                                    data_B[:, :, fold * B_fold:(fold + 1) * B_fold]), axis=2)\n",
    "        #here B is pos and c is neg\n",
    "        label_test = np.concatenate((np.zeros((fold + 1) * C_fold - fold * C_fold),\n",
    "                                    np.ones((fold + 1) * B_fold - fold * B_fold)))\n",
    "        #so here i want A to be pos and b to neg  \n",
    "        data_train = np.concatenate((\n",
    "            data_B[:, :, np.setdiff1d(np.arange(num_B), \n",
    "            np.arange(fold * B_fold, (fold + 1) * B_fold))],\n",
    "            data_A[:, :, np.setdiff1d(np.arange(num_A), \n",
    "            np.arange(fold * A_fold, (fold + 1) * A_fold))]),\n",
    "            axis=2)\n",
    "        label_train = np.concatenate((np.zeros(num_B - (fold + 1) * B_fold + fold * B_fold),\n",
    "                                    np.ones(num_A - (fold + 1) * A_fold + fold * A_fold)))\n",
    "        for timebin in range(T):\n",
    "            model_glm = LogisticRegression(class_weight='balanced') \n",
    "            model_glm.fit(data_train[timebin, :, :].T, label_train)\n",
    "            pred_glm = model_glm.predict_proba(data_test[timebin, :, :].T)\n",
    "            auc_glm.append(roc_auc_score(label_test, pred_glm[:, 1]))\n",
    "            \n",
    "            model_rf = BaggingClassifier(estimator=DecisionTreeClassifier(class_weight = 'balanced'), n_estimators=50, random_state=0)\n",
    "            model_rf.fit(data_train[timebin, :, :].T, label_train)\n",
    "            pred_rf = model_rf.predict_proba(data_test[timebin, :, :].T)\n",
    "            auc_rf.append(roc_auc_score(label_test, pred_rf[:, 1]))\n",
    "        auc['glm'].append(auc_glm)\n",
    "        auc['rf'].append(auc_rf)\n",
    "        for shuffle in range(num_shuffle):\n",
    "            temp_glm_shuffle = []\n",
    "            temp_rf_shuffle = []\n",
    "            label_train = np.random.permutation(label_train)\n",
    "            for timebin in range(T):\n",
    "                model_glm = LogisticRegression(class_weight='balanced')\n",
    "                model_glm.fit(data_train[timebin, :, :].T, label_train)\n",
    "                pred_glm = model_glm.predict_proba(data_test[timebin, :, :].T)\n",
    "                temp_glm_shuffle.append(roc_auc_score(label_test, pred_glm[:, 1]))\n",
    "\n",
    "                model_rf = BaggingClassifier(estimator=DecisionTreeClassifier(class_weight = 'balanced'), n_estimators=50, random_state=0)\n",
    "                model_rf.fit(data_train[timebin, :, :].T, label_train)\n",
    "                pred_rf = model_rf.predict_proba(data_test[timebin, :, :].T)\n",
    "                temp_rf_shuffle.append(roc_auc_score(label_test, pred_rf[:, 1]))\n",
    "            auc_glm_shuffle.append(temp_glm_shuffle)\n",
    "            auc_rf_shuffle.append(temp_rf_shuffle)\n",
    "        auc['glm_shuffle'].append(auc_glm_shuffle)\n",
    "        auc['rf_shuffle'].append(auc_rf_shuffle)\n",
    "    if plot:\n",
    "        __plot_auc_1__(auc, equalize, pre_window)\n",
    "    return auc\n",
    "\n",
    "\n",
    "def __plot_auc_1__(auc_dict, equalize, pre_window):\n",
    "    avg_auc = {}\n",
    "    no_plots = len(auc_dict.keys())\n",
    "    height_fig = math.ceil(no_plots/2)\n",
    "    plt.figure(figsize=(12,4*height_fig))\n",
    "    glm_avg = np.mean(auc_dict['glm'], axis = 0)\n",
    "    glm_sem = sem(auc_dict['glm'], axis = 0)\n",
    "    x =np.linspace(-pre_window, equalize, len(glm_avg))\n",
    "    rf_avg = np.mean(auc_dict['rf'], axis = 0)\n",
    "    rf_sem = sem(auc_dict['rf'], axis = 0)\n",
    "    glm_shuffle_avg = np.mean(np.mean(auc_dict['glm_shuffle'], axis = 1), axis = 0)\n",
    "    glm_shuffle_sem = sem(np.mean(auc_dict['glm_shuffle'], axis = 1), axis = 0)\n",
    "    rf_shuffle_avg = np.mean(np.mean(auc_dict['rf_shuffle'], axis = 1), axis = 0)\n",
    "    rf_shuffle_sem = sem(np.mean(auc_dict['rf_shuffle'], axis = 1), axis = 0)\n",
    "    plt.plot(x, glm_avg, label ='glm')\n",
    "    plt.fill_between(x, glm_avg-glm_sem, glm_avg+glm_sem, alpha = 0.2)\n",
    "    plt.plot(x, rf_avg, label =  'rf')\n",
    "    plt.fill_between(x, rf_avg-rf_sem, rf_avg+rf_sem, alpha = 0.2)\n",
    "    plt.plot(x, glm_shuffle_avg, label = 'glm shuffle')\n",
    "    plt.fill_between(x, glm_shuffle_avg-glm_shuffle_sem, glm_shuffle_avg+glm_shuffle_sem, alpha = 0.2)\n",
    "    plt.plot(x, rf_shuffle_avg, label = 'rf shuffle')\n",
    "    plt.fill_between(x, rf_shuffle_avg-rf_shuffle_sem, rf_shuffle_avg+rf_shuffle_sem, alpha = 0.2)\n",
    "    plt.ylim(.25, 1)\n",
    "    plt.axvline(x=0, color='k', linestyle='--')\n",
    "    plt.legend(bbox_to_anchor=(1,1))\n",
    "    plt.title('Decoder Accuracy')\n",
    "    plt.show()\n",
    "            \n",
    "def __plot_auc__(auc_dict, equalize, pre_window):\n",
    "    avg_auc = {}\n",
    "    no_plots = len(auc_dict.keys())\n",
    "    height_fig = math.ceil(no_plots/2)\n",
    "    i = 1\n",
    "    plt.figure(figsize=(12,4*height_fig))\n",
    "    for key in auc_dict.keys():\n",
    "        glm_avg = np.mean(auc_dict[key]['glm'], axis = 0)\n",
    "        glm_sem = sem(auc_dict[key]['glm'], axis = 0)\n",
    "        x =np.linspace(-pre_window, equalize, len(glm_avg))\n",
    "        rf_avg = np.mean(auc_dict[key]['rf'], axis = 0)\n",
    "        rf_sem = sem(auc_dict[key]['rf'], axis = 0)\n",
    "        glm_shuffle_avg = np.mean(np.mean(auc_dict[key]['glm_shuffle'], axis = 1), axis = 0)\n",
    "        glm_shuffle_sem = sem(np.mean(auc_dict[key]['glm_shuffle'], axis = 1), axis = 0)\n",
    "        rf_shuffle_avg = np.mean(np.mean(auc_dict[key]['rf_shuffle'], axis = 1), axis = 0)\n",
    "        rf_shuffle_sem = sem(np.mean(auc_dict[key]['rf_shuffle'], axis = 1), axis = 0)\n",
    "        avg_auc[key] = [glm_avg, rf_avg, glm_shuffle_avg, rf_shuffle_avg]\n",
    "        plt.subplot(height_fig,2,i)\n",
    "        plt.plot(x, glm_avg, label ='glm')\n",
    "        plt.fill_between(x, glm_avg-glm_sem, glm_avg+glm_sem, alpha = 0.2)\n",
    "        plt.plot(x, rf_avg, label =  'rf')\n",
    "        plt.fill_between(x, rf_avg-rf_sem, rf_avg+rf_sem, alpha = 0.2)\n",
    "        plt.plot(x, glm_shuffle_avg, label = 'glm shuffle')\n",
    "        plt.fill_between(x, glm_shuffle_avg-glm_shuffle_sem, glm_shuffle_avg+glm_shuffle_sem, alpha = 0.2)\n",
    "        plt.plot(x, rf_shuffle_avg, label = 'rf shuffle')\n",
    "        plt.fill_between(x, rf_shuffle_avg-rf_shuffle_sem, rf_shuffle_avg+rf_shuffle_sem, alpha = 0.2)\n",
    "        plt.title(f'Trained for {key}')\n",
    "        plt.ylim(.4, 1)\n",
    "        plt.axvline(x=0, color='k', linestyle='--')\n",
    "        if i == 2:\n",
    "            plt.legend(bbox_to_anchor=(1,1))\n",
    "        i += 1\n",
    "    plt.suptitle('Decoder Accuracy')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
