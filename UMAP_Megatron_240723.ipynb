{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5094bbe7-6b6a-4457-b56a-0d1612c6cd00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72b2ea0b-6e11-4f6c-a885-89af6af41d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cylouvain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfutures\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcylouvain\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cylouvain'"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import cylouvain\n",
    "import matplotlib as mpl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from matplotlib import cm\n",
    "from matplotlib import pyplot as plt\n",
    "from phylib.io.model import load_model\n",
    "from sklearn.preprocessing import normalize\n",
    "from umap import umap_ as umap\n",
    "from wavemap_paper.helper_functions import plot_confusion_matrix\n",
    "from wavemap_paper.helper_functions import plot_inverse_mapping\n",
    "from wavemap_paper.helper_functions import RAND_STATE, set_rand_state\n",
    "from wavemap_paper.helper_functions import train_gridsearch_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a2705f-484b-4bc1-9ad0-7cfd7b3916ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Constants\n",
    "BASE_DIR = r'D:\\pc_lab\\RCE\\finished_proc\\phy_curation'\n",
    "SAVE_PATH = r'D:\\pc_lab\\RCE\\meanWave_clust_240723_1.npy'  # Path to save the waveform data\n",
    "\n",
    "def process_folder(folder):\n",
    "    cluster_info_path = os.path.join(folder, 'phy', 'cluster_info.tsv')\n",
    "    params_path = os.path.join(folder, 'phy', 'params.py')\n",
    "    recording_name = os.path.basename(folder)\n",
    "    \n",
    "    # Read the TSV file\n",
    "    try:\n",
    "        cluster_info = pd.read_csv(cluster_info_path, sep='\\t')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {cluster_info_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        good_clusters = cluster_info[\n",
    "            (cluster_info['group'] == 'good') & \n",
    "            (cluster_info['fr'] > 0.5)\n",
    "        ][['cluster_id', 'fr']]\n",
    "        \n",
    "        # Load the TemplateModel\n",
    "        model = load_model(params_path)\n",
    "        \n",
    "        # Initialize a list to store the mean waveforms, cluster IDs, firing rates, and recording names\n",
    "        mean_waveforms = []\n",
    "        cluster_ids = []\n",
    "        firing_rates = []\n",
    "        recording_names = []\n",
    "        \n",
    "        for _, row in good_clusters.iterrows():\n",
    "            cluster_id = row['cluster_id']\n",
    "            firing_rate = row['fr']\n",
    "            \n",
    "            # Get cluster spike waveforms\n",
    "            waveforms = model.get_cluster_spike_waveforms(cluster_id)[:, :, 0]\n",
    "            # Calculate the mean waveform and normalize it\n",
    "            mean_waveform = waveforms.mean(axis=0)\n",
    "            norm_mean_waveform = normalize(mean_waveform.reshape(1, -1), norm='max').squeeze()\n",
    "            mean_waveforms.append(norm_mean_waveform)\n",
    "            cluster_ids.append(cluster_id)\n",
    "            firing_rates.append(firing_rate)\n",
    "            recording_names.append(recording_name)\n",
    "        \n",
    "        return list(zip(mean_waveforms, cluster_ids, firing_rates, recording_names))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data in {folder}: {e}\")\n",
    "        return []\n",
    "\n",
    "def main():\n",
    "    # Retrieve all recording folders\n",
    "    folders = [os.path.join(BASE_DIR, f) for f in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, f))]\n",
    "    \n",
    "    # Process each folder\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        for result in executor.map(process_folder, folders):\n",
    "            if result:\n",
    "                results.extend(result)\n",
    "\n",
    "    # Combine all waveforms, cluster IDs, firing rates, and recording names into a single list\n",
    "    if not results:\n",
    "        print(\"No waveforms found.\")\n",
    "        return\n",
    "\n",
    "    normWFs_array = np.array([r[0] for r in results])\n",
    "    cluster_ids = np.array([r[1] for r in results])\n",
    "    firing_rates = np.array([r[2] for r in results])\n",
    "    recording_names = np.array([r[3] for r in results])\n",
    "\n",
    "    # Save the results to a file\n",
    "    np.save(SAVE_PATH, {'waveforms': normWFs_array, 'cluster_ids': cluster_ids, 'firing_rates': firing_rates, 'recording_names': recording_names})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# Load the saved data\n",
    "SAVED_PATH = r\"D:\\pc_lab\\RCE\\meanWave_clust_240723_1.npy\"  # Created by iterating through every recording on external hard drive (Cyborg)\n",
    "data = np.load(SAVED_PATH, allow_pickle=True).item()\n",
    "# Load normWFs directly from the saved data\n",
    "normWFs = data['waveforms']\n",
    "cluster_ids = data['cluster_ids']\n",
    "\n",
    "# Identify the rows that contain 1 in normWFs\n",
    "rows_with_1 = np.any(normWFs == 1, axis=1)\n",
    "\n",
    "# Multiply the identified rows by -1 to apply the necessary transformation\n",
    "normWFs[rows_with_1] *= -1\n",
    "\n",
    "set_rand_state(RAND_STATE)\n",
    "\n",
    "reducer = umap.UMAP(random_state = RAND_STATE, n_neighbors = 15)\n",
    "mapper = reducer.fit(normWFs)\n",
    "\n",
    "G = nx.from_scipy_sparse_array(mapper.graph_)\n",
    "\n",
    "clustering = cylouvain.best_partition(G, resolution = 2)\n",
    "clustering_solution = list(clustering.values())\n",
    "\n",
    "embedding = reducer.fit_transform(normWFs)\n",
    "\n",
    "umap_df = pd.DataFrame(embedding, columns=('x', 'y'))\n",
    "umap_df['waveform'] = list(normWFs)\n",
    "umap_df['cluster_id'] = clustering_solution\n",
    "\n",
    "cmap = plt.get_cmap(\"turbo\")\n",
    "colors = cmap(np.linspace(0, 1, len(set(clustering_solution))))\n",
    "umap_df['cluster_color'] = [colors[i] for i in clustering_solution]\n",
    "plt.scatter(umap_df['x'].tolist(), umap_df['y'].tolist(),\n",
    "marker='o', c=umap_df['cluster_id'].tolist(), cmap='turbo')\n",
    "\n",
    "f,arr = plt.subplots(1)\n",
    "\n",
    "for i,row in enumerate(umap_df['waveform'].tolist()):\n",
    "    arr.plot(umap_df['waveform'].tolist()[i],c=umap_df['cluster_color'].tolist()[i],alpha=0.5)\n",
    "\n",
    "umap_df.to_csv('umap_df.csv')\n",
    "\n",
    "plot_inverse_mapping(reducer, umap_df)\n",
    "\n",
    "umap_model, conf_mat = train_gridsearch_classifier(umap_df)\n",
    "\n",
    "plot_confusion_matrix(conf_mat,umap_df)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "xgbModel = xgb.XGBClassifier(umap_model.best_params_)\n",
    "xgbModel.fit(umap_df['waveform'].tolist(),umap_df['cluster_id'].tolist())\n",
    "explainer = shap.TreeExplainer(xgbModel)\n",
    "\n",
    "umap_cmap = mpl.colors.ListedColormap(colors, name='umap_cmap')\n",
    "shap_values = explainer.shap_values(umap_df['waveform'].tolist())\n",
    "shap.summary_plot(shap_values, color = umap_cmap)\n",
    "\n",
    "# Create a copy of umap_df\n",
    "umap_df_detail = umap_df.copy()\n",
    "\n",
    "# Append firing rates, recording names, and cluster_ids (renamed to unit_id)\n",
    "umap_df_detail['firing_rate'] = data['firing_rates']\n",
    "umap_df_detail['recording_name'] = data['recording_names']\n",
    "umap_df_detail['unit_id'] = data['cluster_ids']\n",
    "\n",
    "# Display the updated DataFrame\n",
    "umap_df_detail.to_csv('umap_df_detail.csv')\n",
    "\n",
    "# Select only the columns that should be averaged\n",
    "columns_to_average = ['x', 'y', 'firing_rate']\n",
    "waveform_means = umap_df_detail.groupby('cluster_id')['waveform'].apply(lambda x: np.mean(np.vstack(x), axis=0))\n",
    "\n",
    "# Group by cluster_id and calculate the mean for the selected columns\n",
    "cluster_averages = umap_df_detail.groupby('cluster_id')[columns_to_average].mean()\n",
    "\n",
    "# Include the averaged waveforms\n",
    "cluster_averages['waveform'] = waveform_means\n",
    "\n",
    "# If cluster_color should be included, it can be taken from one of the rows for each cluster_id\n",
    "cluster_colors = umap_df_detail.groupby('cluster_id')['cluster_color'].first()\n",
    "\n",
    "# Combine the averaged DataFrame with the cluster_colors\n",
    "cluster_averages['cluster_color'] = cluster_colors\n",
    "\n",
    "# Reset the index if you want cluster_id to be a column\n",
    "cluster_averages.reset_index(inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "cluster_averages\n",
    "\n",
    "cluster_averages.to_csv('cluster_averages.csv')\n",
    "\n",
    "# Plot the waveforms from cluster_averages\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Store line objects to create custom legend\n",
    "lines = []\n",
    "\n",
    "# Iterate over each row to plot the waveform and prepare legend entries\n",
    "legend_entries = []\n",
    "for _, row in cluster_averages.iterrows():\n",
    "    line, = plt.plot(row['waveform'], color=row['cluster_color'], alpha=0.7)\n",
    "    lines.append(line)\n",
    "    legend_entries.append(f\"Cluster {row['cluster_id']} (FR: {row['firing_rate']:.2f})\")\n",
    "\n",
    "# Adding the legend with thicker lines\n",
    "plt.legend([plt.Line2D([0], [0], color=line.get_color(), linewidth=3) for line in lines], legend_entries, loc='upper right', bbox_to_anchor=(1.15, 1))\n",
    "\n",
    "plt.title('Average Waveforms by Cluster')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "# Count the occurrences of each cluster_id\n",
    "cluster_id_counts = umap_df['cluster_id'].value_counts()\n",
    "\n",
    "# Display the result\n",
    "cluster_id_counts\n",
    "\n",
    "def calc_trough_to_peak_duration(waveform):\n",
    "    \"\"\"\n",
    "    Calculate the trough to peak duration in milliseconds.\n",
    "    \n",
    "    Parameters:\n",
    "    waveform (array): The waveform array.\n",
    "    \n",
    "    Returns:\n",
    "    float: Trough to peak duration in milliseconds.\n",
    "    \"\"\"\n",
    "    # Find the index of the most negative value (trough)\n",
    "    trough_index = np.argmin(waveform)\n",
    "    \n",
    "    # Find the index of the most positive value (peak) after the trough\n",
    "    peak_index = np.argmax(waveform[trough_index:]) + trough_index\n",
    "    \n",
    "    # The duration is the difference between the peak and trough indices\n",
    "    duration_samples = peak_index - trough_index\n",
    "    \n",
    "    # Convert the duration from samples to milliseconds\n",
    "    duration_ms = duration_samples * 0.00005 * 1000  # 0.00005 seconds per sample\n",
    "    \n",
    "    return duration_ms\n",
    "\n",
    "# Calculate and print spike durations\n",
    "for i, waveform in enumerate(cluster_averages['waveform']):\n",
    "    duration = calc_trough_to_peak_duration(waveform)\n",
    "    print(f\"Trough-Peak duration for waveform {i}: {duration:.2f} ms\")\n",
    "    \n",
    "umap_df.to_pickle('umap_df.pkl')\n",
    "umap_df_detail.to_pickle('umap_df_detail.pkl')\n",
    "\n",
    "# Create a color map\n",
    "cmap = plt.get_cmap(\"turbo\")\n",
    "colors = cmap(np.linspace(0, 1, len(set(clustering_solution))))\n",
    "umap_df['cluster_color'] = [colors[i] for i in clustering_solution]\n",
    "\n",
    "# Plotting the UMAP projection\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(umap_df['x'], umap_df['y'], marker='o', c=umap_df['cluster_id'], cmap='turbo', alpha=0.7)\n",
    "plt.title('UMAP Visualization of Waveform Characteristics')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "\n",
    "# Adding a legend for each cluster with firing rates\n",
    "# Assume `cluster_averages` dataframe exists with `cluster_id` and `firing_rate`\n",
    "legend_handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=c, markersize=6) \n",
    "                  for c in colors]\n",
    "legend_labels = [f'Cluster {i} (FR: {row[\"firing_rate\"]:.2f})' for i, row in cluster_averages.iterrows()]\n",
    "plt.legend(handles=legend_handles, labels=legend_labels, title=\"Clusters & Firing Rates\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4480f9-2e7b-47e8-88c5-c293ab2c9cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp_env",
   "language": "python",
   "name": "lfp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
