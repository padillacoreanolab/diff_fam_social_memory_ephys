{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boris_extraction as boris\n",
    "import multirecording_spikeanalysis as spike\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import sem\n",
    "from itertools import combinations\n",
    "def hex_2_rgb(hex_color): # Orange color\n",
    "    rgb_color = tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (1, 3, 5))\n",
    "    return rgb_color\n",
    "\n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):   \n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):   \n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return(pickle.load(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wilcoxon Single Cell Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fam_score(acquisition_vs_novel, recall_vs_cagemate, recall_vs_novel, cagemate_vs_novel, acquisition_vs_recall, id_score):\n",
    "    fam_score = 0\n",
    "    if acquisition_vs_novel == 'not significant':\n",
    "        if recall_vs_cagemate != 'not significant':\n",
    "            fam_score +=1\n",
    "        if recall_vs_novel != 'not significant':\n",
    "            fam_score +=1\n",
    "        if cagemate_vs_novel != 'not significant':\n",
    "            fam_score +=2\n",
    "        if (id_score != 0):\n",
    "            if id_score == 'familiarity?':\n",
    "                fam_score = fam_score\n",
    "            else:\n",
    "                fam_score += (-2)\n",
    "        if acquisition_vs_recall != 'not significant':\n",
    "            fam_score += 1\n",
    "    return fam_score\n",
    "\n",
    "def get_id_score(acquisition_vs_novel, recall_vs_cagemate, recall_vs_novel, cagemate_vs_novel, acquisition_vs_recall):\n",
    "    id_score = 0\n",
    "    if acquisition_vs_recall == 'not significant':\n",
    "        if (recall_vs_cagemate != 'not significant') & (cagemate_vs_novel != 'not significant'):\n",
    "                id_score = 'cagemate'\n",
    "        if (recall_vs_novel != 'not significant') & (recall_vs_cagemate != 'not significant'):\n",
    "                id_score = 'familiar'\n",
    "        if (recall_vs_novel != 'not significant') & (cagemate_vs_novel != 'not significant'):\n",
    "                id_score = 'novel'\n",
    "        if (recall_vs_novel != 'not significant') & (cagemate_vs_novel != 'not significant') & (recall_vs_cagemate != 'not significant'):\n",
    "             id_score = 'familiarity?'\n",
    "    if acquisition_vs_recall != 'not significant':\n",
    "         if (recall_vs_novel != 'not significant') & (recall_vs_cagemate != 'not significant'):\n",
    "                id_score = 'recall'\n",
    "    return id_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           #offset included                    offset excluded \n",
    "# 2, 5, -2 =      80                                 72\n",
    "# 1 , 5, -2 =     65                                  65\n",
    "# 0, 6, -1 =      65                                       \n",
    "# 1, 5, -1 =      64                                  58\n",
    "# 2, 4, 1 =       62\n",
    "# 3, 5, 0 =       62\n",
    "# 3, 5, -1 =      61\n",
    "# 3, 5, -2 =      61                                  \n",
    "# 2, 4, -1 =      71                                  73\n",
    "# 2, 4, 0 =       59         \n",
    "# 3, 4, 0 =       59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pca_analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m baseline_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      3\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpca_analysis\u001b[49m\u001b[38;5;241m.\u001b[39mfishers_exact_wilcox(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnovel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcagemate\u001b[39m\u001b[38;5;124m'\u001b[39m, equalize \u001b[38;5;241m=\u001b[39m equalize, baseline_window\u001b[38;5;241m=\u001b[39mbaseline_window,offset\u001b[38;5;241m=\u001b[39m offset, event3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m      5\u001b[0m pca_analysis\u001b[38;5;241m.\u001b[39mfishers_exact_wilcox(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfamiliar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124macquisition\u001b[39m\u001b[38;5;124m'\u001b[39m,equalize \u001b[38;5;241m=\u001b[39m equalize, baseline_window\u001b[38;5;241m=\u001b[39mbaseline_window,offset\u001b[38;5;241m=\u001b[39m offset, event3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pca_analysis' is not defined"
     ]
    }
   ],
   "source": [
    "equalize = 2\n",
    "baseline_window = 2\n",
    "offset = 0\n",
    "print(pca_analysis.fishers_exact_wilcox('novel', 'cagemate', equalize = equalize, baseline_window=baseline_window,offset= offset, event3 = None))\n",
    "pca_analysis.fishers_exact_wilcox('familiar', 'acquisition',equalize = equalize, baseline_window=baseline_window,offset= offset, event3 = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for comparison in ['2s novel vs 2s baseline', '2s cagemate vs 2s baseline', '2s familiar vs 2s baseline', '2s acquisition vs 2s baseline']:\n",
    "    df = phase3_collection.wilcox_dfs[comparison]\n",
    "    df_list.append(df)\n",
    "\n",
    "is_first = True \n",
    "for df in df_list:\n",
    "    if is_first:\n",
    "        master_df = df[['Subject', 'Recording', 'original unit id', \n",
    "                            'Event','event1 vs event2']]\n",
    "        is_first = False\n",
    "    else: \n",
    "        temp_df = df[['Subject', 'Recording', 'original unit id', \n",
    "                            'Event', 'event1 vs event2']]\n",
    "        master_df = master_df.merge(temp_df,  on=['Subject', 'Recording', 'original unit id'], how = 'left')\n",
    "    \n",
    "#novel vs baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.columns = ['Subject',\n",
    " 'Recording',\n",
    " 'original unit id',\n",
    " 'Event_x',\n",
    " 'novel vs baseline',\n",
    " 'Event_y',\n",
    " 'cagemate vs baseline',\n",
    " 'Event_x',\n",
    " 'familiar vs baseline',\n",
    " 'Event_y',\n",
    " 'acquisition vs baseline' ]\n",
    "master_df = master_df[['original unit id',\n",
    " 'novel vs baseline',\n",
    " 'cagemate vs baseline',\n",
    " 'familiar vs baseline',\n",
    " 'acquisition vs baseline'\n",
    " ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_cells(novel, cagemate, fam, acquisition):\n",
    "    group = ''\n",
    "    if novel != 'not significant':\n",
    "        group = 'novel'\n",
    "    if cagemate != 'not significant':\n",
    "        group = group + 'cagemate' \n",
    "    if fam != 'not significant':\n",
    "        group = group + 'fam'\n",
    "    if acquisition != 'not significant':\n",
    "        group = group + 'acquisition'\n",
    "    return group\n",
    "\n",
    "master_df['cell group'] = master_df.apply(lambda row: group_cells(row['novel vs baseline'],\n",
    "                                                                  row['cagemate vs baseline'],\n",
    "                                                                  row['familiar vs baseline'],\n",
    "                                                                  row['acquisition vs baseline']), axis = 1)\n",
    "results = master_df.groupby('cell group').count()\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
