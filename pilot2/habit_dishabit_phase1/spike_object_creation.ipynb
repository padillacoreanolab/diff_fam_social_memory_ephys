{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "from scipy.stats import sem\n",
    "from matplotlib.lines import Line2D\n",
    "import sys\n",
    "sys.path.append(\"../../spike\")\n",
    "import multirecording_spikeanalysis as spike\n",
    "import pickle\n",
    "\n",
    "def hex_2_rgb(hex_color): # Orange color\n",
    "    rgb_color = tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (1, 3, 5))\n",
    "    return rgb_color\n",
    "\n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):   \n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):   \n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['11_cage_p1_aggregated', '11_nov_p1_aggregated', '12_cage_p1_aggregated', '12_nov_p1_aggregated', '13_cage_p1_aggregated', '13_nov_p1_aggregated', '21_cage_p1_aggregated', '21_nov_p1_aggregated', '22_cage_p1_aggregated', '22_nov_p1_aggregated', '23_cage_p1_aggregated', '23_nov_p1_aggregated', '24_cage_p1_aggregated', '24_nov_p1_aggregated', '31_cage_p1_aggregated', '31_nov_p1_aggregated', '32_cage_p1_aggregated', '32_nov_p1_aggregated', '33_cage_p1_aggregated', '33_nov_p1_aggregated', '41_cage_p1_aggregated', '41_nov_p1_aggregated', '44_cage_p1_aggregated', '44_nov_p1_aggregated'])\n"
     ]
    }
   ],
   "source": [
    "behavior_dicts = unpickle_this('behavior_dicts.pkl')\n",
    "print(behavior_dicts.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  11_cage_p1_merged.rec\n",
      "loading  12_cage_p1_merged.rec\n",
      "loading  13_cage_p1_merged.rec\n",
      "loading  21_cage_p1_merged.rec\n",
      "loading  22_cage_p1_merged.rec\n",
      "loading  23_cage_p1_merged.rec\n",
      "loading  31_cage_p1_merged.rec\n",
      "loading  32_cage_p1_merged.rec\n",
      "loading  33_cage_p1_merged.rec\n",
      "loading  41_cage_p1_merged.rec\n",
      "loading  44_cage_p1_merged.rec\n",
      "Please assign event dictionaries to each recording\n",
      "as recording.event_dict\n",
      "event_dict = {event name(str): np.array[[start(ms), stop(ms)]...]\n",
      "Please assign subjects to each recording as recording.subject\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cagemate_collection = spike.EphysRecordingCollection(r\"C:\\Users\\megha\\UFL Dropbox\\Meghan Cum\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\Habituation_Dishabituation (phase 1)\\sorted\\cagemate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_cage_p1_aggregated\n",
      "12_cage_p1_aggregated\n",
      "13_cage_p1_aggregated\n",
      "21_cage_p1_aggregated\n",
      "22_cage_p1_aggregated\n",
      "23_cage_p1_aggregated\n",
      "31_cage_p1_aggregated\n",
      "32_cage_p1_aggregated\n",
      "33_cage_p1_aggregated\n",
      "41_cage_p1_aggregated\n",
      "44_cage_p1_aggregated\n"
     ]
    }
   ],
   "source": [
    "for recording_name, recording in cagemate_collection.collection.items():\n",
    "    subject = str(int(recording_name.split('_')[0])/10)\n",
    "    recording_pattern = (recording_name.split('_')[0] + '_' +\n",
    "                         recording_name.split('_')[1] + '_' +\n",
    "                         recording_name.split('_')[2] + '_' +\n",
    "                         'aggregated')\n",
    "    recording.event_dict = behavior_dicts[recording_pattern]\n",
    "    print(recording_pattern)\n",
    "    recording.subject = subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading  11_nov_p1_merged.rec\n",
      "loading  12_nov_p1_merged.rec\n",
      "loading  13_nov_p1_merged.rec\n",
      "loading  21_nov_p1_merged.rec\n",
      "loading  22_nov_p1_merged.rec\n",
      "loading  23_nov_p1_merged.rec\n",
      "loading  24_nov_p1_merged.rec\n",
      "loading  32_nov_p1_merged.rec\n",
      "loading  33_nov_p1_merged.rec\n",
      "loading  41_nov_p1_merged.rec\n",
      "loading  44_nov_p1_merged.rec\n",
      "Please assign event dictionaries to each recording\n",
      "as recording.event_dict\n",
      "event_dict = {event name(str): np.array[[start(ms), stop(ms)]...]\n",
      "Please assign subjects to each recording as recording.subject\n"
     ]
    }
   ],
   "source": [
    "novel_collection = spike.EphysRecordingCollection(r\"C:\\Users\\megha\\UFL Dropbox\\Meghan Cum\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\Habituation_Dishabituation (phase 1)\\sorted\\novel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11_nov_p1_aggregated\n",
      "12_nov_p1_aggregated\n",
      "13_nov_p1_aggregated\n",
      "21_nov_p1_aggregated\n",
      "22_nov_p1_aggregated\n",
      "23_nov_p1_aggregated\n",
      "24_nov_p1_aggregated\n",
      "32_nov_p1_aggregated\n",
      "33_nov_p1_aggregated\n",
      "41_nov_p1_aggregated\n",
      "44_nov_p1_aggregated\n"
     ]
    }
   ],
   "source": [
    "for recording_name, recording in novel_collection.collection.items():\n",
    "    subject = str(int(recording_name.split('_')[0])/10)\n",
    "    recording_pattern = (recording_name.split('_')[0] + '_' +\n",
    "                         recording_name.split('_')[1] + '_' +\n",
    "                         recording_name.split('_')[2] + '_' +\n",
    "                         'aggregated')\n",
    "    recording.event_dict = behavior_dicts[recording_pattern]\n",
    "    print(recording_pattern)\n",
    "    recording.subject = subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_this(novel_collection, 'novel_collection.pkl')\n",
    "pickle_this(cagemate_collection, 'cagemate_collection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
