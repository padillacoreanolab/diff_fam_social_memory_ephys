{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "sys.path.append(\"../../spike\")\n",
    "import multirecording_spikeanalysis as spike\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.patches as mpatches\n",
    "from itertools import combinations\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['figure.titleweight'] = 'bold'\n",
    "\n",
    "def hex_2_rgb(hex_color): # Orange color\n",
    "    rgb_color = tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (1, 3, 5))\n",
    "    return rgb_color\n",
    "\n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):   \n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):   \n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set to analyze\n"
     ]
    }
   ],
   "source": [
    "cagemate_collection = unpickle_this('cagemate_collection.pkl')\n",
    "\n",
    "cagemate_analysis = spike.SpikeAnalysis_MultiRecording(cagemate_collection,\n",
    "                                                  timebin = 100,\n",
    "                                                  ignore_freq =  0.5,\n",
    "                                                  smoothing_window = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set to analyze\n"
     ]
    }
   ],
   "source": [
    "novel_collection = unpickle_this('novel_collection.pkl')\n",
    "\n",
    "novel_analysis = spike.SpikeAnalysis_MultiRecording(novel_collection,\n",
    "                                                  timebin = 100,\n",
    "                                                  ignore_freq =  0.5,\n",
    "                                                  smoothing_window = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cagemate_pc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcagemate_analysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPCA_trajectories\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#eo_dis = pca_analysis.LOO_PCA(2, 2, 0.9, events = ['acquisition', 'recall', 'cagemate', 'novel'])\u001b[39;00m\n\u001b[0;32m      3\u001b[0m var \u001b[38;5;241m=\u001b[39m cagemate_pc_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplained variance\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\megha\\Documents\\GitHub\\diff_fam_social_memory_ephys\\pilot2\\habit_dishabit_phase1\\../../spike\\multirecording_spikeanalysis.py:1821\u001b[0m, in \u001b[0;36mSpikeAnalysis_MultiRecording.PCA_trajectories\u001b[1;34m(self, equalize, pre_window, post_window, plot, save, events, recordings, d, azim, elev)\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPCA_trajectories\u001b[39m(\n\u001b[0;32m   1787\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1788\u001b[0m     equalize,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1797\u001b[0m     elev\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m   1798\u001b[0m ):\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1800\u001b[0m \u001b[38;5;124;03m    calculates a PCA matrix where each data point represents a timebin.\u001b[39;00m\n\u001b[0;32m   1801\u001b[0m \u001b[38;5;124;03m    PCA space is calculated from a matrix of all units and all timebins\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1819\u001b[0m \n\u001b[0;32m   1820\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1821\u001b[0m     pc_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPCA_matrix_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequalize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecordings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1822\u001b[0m     transformed_matrix \u001b[38;5;241m=\u001b[39m pc_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformed data\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m events \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\megha\\Documents\\GitHub\\diff_fam_social_memory_ephys\\pilot2\\habit_dishabit_phase1\\../../spike\\multirecording_spikeanalysis.py:1746\u001b[0m, in \u001b[0;36mSpikeAnalysis_MultiRecording.PCA_matrix_generation\u001b[1;34m(self, equalize, pre_window, post_window, events, recordings)\u001b[0m\n\u001b[0;32m   1744\u001b[0m     is_first_event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1746\u001b[0m     PCA_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPCA_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_averages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1747\u001b[0m     next_key \u001b[38;5;241m=\u001b[39m [event] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mint\u001b[39m((equalize \u001b[38;5;241m+\u001b[39m pre_window \u001b[38;5;241m+\u001b[39m post_window) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimebin)\n\u001b[0;32m   1748\u001b[0m     PCA_event_key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((PCA_event_key, next_key), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "cagemate_pc_dict = cagemate_analysis.PCA_trajectories(3, 1, d = 3)\n",
    "#eo_dis = pca_analysis.LOO_PCA(2, 2, 0.9, events = ['acquisition', 'recall', 'cagemate', 'novel'])\n",
    "var = cagemate_pc_dict['explained variance']\n",
    "total_var = 0\n",
    "for varl in var[0:12]: \n",
    "    total_var =+ total_var + varl\n",
    "    print(total_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
