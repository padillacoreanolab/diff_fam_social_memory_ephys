{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb940c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import spike.spike_analysis.spike_collection as sc\n",
    "import spike.spike_analysis.spike_recording as sr\n",
    "import spike.spike_analysis.firing_rate_calculations as fr\n",
    "import spike.spike_analysis.normalization as norm\n",
    "import spike.spike_analysis.single_cell as single_cell\n",
    "import spike.spike_analysis.spike_collection as collection\n",
    "import spike.spike_analysis.zscoring as zscoring\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import behavior.boris_extraction as boris\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Formatting for Pandas\n",
    "\n",
    "# %%\n",
    "pd.set_option('display.max_colwidth', 0)  # 0 means unlimited in newer pandas versions\n",
    "\n",
    "# Show all rows\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "# Show all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Donâ€™t truncate column contents\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "# Expand the display to the full width of the screen\n",
    "pd.set_option(\"display.width\", 0)\n",
    "\n",
    "\n",
    "# %%\n",
    "spike_collection_json_path = r'C:\\Users\\thoma\\Code\\ResearchCode\\diff_fam_social_memory_ephys\\spike_collection.json\\spike_collection.json'\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Reloading Main 2 Packages\n",
    "\n",
    "# %%\n",
    "import importlib\n",
    "importlib.reload(sc)\n",
    "importlib.reload(zscoring)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Loading in SpikeCollection Object with Recordings and their corresponding event dicts\n",
    "\n",
    "# %%\n",
    "sp = sc.SpikeCollection.load_collection(spike_collection_json_path)\n",
    "\n",
    "# %%\n",
    "rec_events = sp.recordings[0].event_dict\n",
    "\n",
    "# get unique event names from rec_events dictionary\n",
    "event_names = list(rec_events.keys())\n",
    "print(\"Unique event names:\", event_names)\n",
    "\n",
    "# %% [markdown]\n",
    "# #### Unique event names: ['alone_rewarded', 'alone_rewarded_baseline', 'high_comp', 'high_comp_lose', 'high_comp_lose_baseline', 'high_comp_win', 'high_comp_win_baseline', 'lose', 'low_comp', 'low_comp_lose', 'low_comp_lose_baseline', 'low_comp_win', 'low_comp_win_baseline', 'overall_pretone', 'win']\n",
    "# \n",
    "\n",
    "# %% [markdown]\n",
    "# ### Verifying it's in timestamps not ms\n",
    "\n",
    "# %%\n",
    "# Pick any one recording and unit\n",
    "recording = sp.recordings[0]  # or choose a specific one\n",
    "unit_id = list(recording.unit_timestamps.keys())[0]  # get the first available good unit\n",
    "\n",
    "# Extract the raw spike timestamps\n",
    "raw_spikes = recording.unit_timestamps[unit_id]\n",
    "\n",
    "# Show the first few spikes\n",
    "print(f\"Raw spike timestamps for unit {unit_id}:\")\n",
    "print(raw_spikes[:10])\n",
    "\n",
    "# Convert to milliseconds\n",
    "converted_spikes_ms = raw_spikes * (1000 / recording.sampling_rate)\n",
    "print(\"\\nConverted to milliseconds:\")\n",
    "print(converted_spikes_ms[:10])\n",
    "\n",
    "# Also print min/max to check range\n",
    "print(f\"\\nMin raw spike: {raw_spikes.min()} | Max raw spike: {raw_spikes.max()}\")\n",
    "print(f\"Min spike time in ms: {converted_spikes_ms.min():.2f} ms | Max: {converted_spikes_ms.max():.2f} ms\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Z-Score for an event using baselines of all events in a recording\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def run_zscore_global_baseline(recording, event_name, pre_window=10, SD=1.65, verbose=False):\n",
    "    \"\"\"\n",
    "    Z-score event firing rates using a *pooled* baseline (all event types) per unit.\n",
    "    This function calculates the z-score of firing rates for a specific event type\n",
    "    based on a global baseline computed from all event types in the recording.\n",
    "    Parameters:\n",
    "    - recording: SpikeRecording object containing spike data and events.\n",
    "    - event_name: Name of the event type to analyze.\n",
    "    - pre_window: Duration in seconds before the event to use for baseline calculation.\n",
    "    - SD: Number of standard deviations to use for significance thresholding.\n",
    "    - verbose: If True, prints additional information during processing.\n",
    "    Returns:\n",
    "    - A pandas DataFrame containing the z-scores and significance of firing rates for each unit\n",
    "    for the specified event type.\n",
    "    \"\"\"\n",
    "    # Step 1: Pool all baseline windows across all events for each unit\n",
    "    global_baseline_counts = {}\n",
    "    units = getattr(recording, \"good_units\", None) # get good units if available\n",
    "    if units is None: # if not, use labels_dict\n",
    "        units = [unit_id for unit_id, label in recording.labels_dict.items() if label == \"good\"]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Using labels_dict to determine good units.\")\n",
    "            print(f\"Good units found: {units}\\n\\nFrom labels_dict: {recording.labels_dict}\\n\\n\")\n",
    "\n",
    "    # Initialize global baseline list per unit\n",
    "    for unit_id in units:\n",
    "        global_baseline_counts[unit_id] = []\n",
    "    if verbose:\n",
    "        print(f\"Gloabal baseline counts initialized for units: {global_baseline_counts}\\n\")    \n",
    "\n",
    "    # Loop through all event types and pool all baselines\n",
    "    # creates a list of baseline counts for each unit\n",
    "    for ev_type, event_windows in recording.event_dict.items():\n",
    "        for unit_id in units:\n",
    "            spikes = recording.unit_timestamps[unit_id] # number of spikes for this unit\n",
    "            spikes_ms = spikes * (1000 / recording.sampling_rate) # convert to milliseconds since event_windows are in ms\n",
    "\n",
    "            for window in event_windows:\n",
    "                start_event = window[0]\n",
    "                start_baseline = start_event - int(pre_window * 1000)\n",
    "                if verbose:\n",
    "                    print(f\"For window {window}, start_event: {start_event}, start_baseline: {start_baseline}, pre_window: {pre_window}\")\n",
    "\n",
    "                end_baseline = start_event\n",
    "                baseline_count = np.sum((spikes_ms >= start_baseline) & (spikes_ms < end_baseline))\n",
    "                global_baseline_counts[unit_id].append(baseline_count) # list of counts for this unit appended to global_baseline_counts\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Unit {unit_id}, Event {ev_type}, Baseline count: {baseline_count} in {global_baseline_counts}\\n\")\n",
    "\n",
    "    # Step 2: Compute global baseline mean and SD per unit using numpy\n",
    "    baseline_mean = {u: np.mean(c) for u, c in global_baseline_counts.items()}\n",
    "    baseline_sd = {u: np.std(c) for u, c in global_baseline_counts.items()}\n",
    "\n",
    "    # Step 3: For the target event, calculate z-scores\n",
    "    event_windows = recording.event_dict[event_name]\n",
    "    event_firing = {}\n",
    "    rows = []\n",
    "    for unit_id in units:\n",
    "        spikes = recording.unit_timestamps[unit_id]\n",
    "        spikes_ms = spikes * (1000 / recording.sampling_rate)\n",
    "        event_counts = []\n",
    "        for window in event_windows:\n",
    "            start_event = window[0]\n",
    "            end_event = window[1]\n",
    "            event_count = np.sum((spikes_ms >= start_event) & (spikes_ms < end_event)) # count spikes in the event window using masking\n",
    "            event_counts.append(event_count)\n",
    "\n",
    "        # getting all the important values for z-score calculation per unit\n",
    "        ev_mean = np.mean(event_counts)\n",
    "        b_mean = baseline_mean[unit_id]\n",
    "        b_sd = baseline_sd[unit_id]\n",
    "\n",
    "        # Calculate z-score\n",
    "        zscore = np.nan if b_sd == 0 else (ev_mean - b_mean) / b_sd \n",
    "\n",
    "\n",
    "        # significance determination based on SD threshold given\n",
    "        sig = \"not sig\"\n",
    "        if not np.isnan(zscore):\n",
    "            if zscore > SD:\n",
    "                sig = \"increase\"\n",
    "            elif zscore < -SD:\n",
    "                sig = \"decrease\"\n",
    "\n",
    "        rows.append({\n",
    "            \"Recording\": recording.name,\n",
    "            \"Event name\": event_name,\n",
    "            \"Unit number\": unit_id,\n",
    "            \"Global Pre-event M\": b_mean,\n",
    "            \"Global Pre-event SD\": b_sd,\n",
    "            \"Event M\": ev_mean,\n",
    "            \"Event Z-Score\": zscore,\n",
    "            \"sig\": sig\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "# %%\n",
    "rec = sp.recordings[0]\n",
    "event_name = \"alone_rewarded\"  # or any event you know exists\n",
    "\n",
    "df = run_zscore_global_baseline(rec, event_name, pre_window=10, SD=1.65)\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
