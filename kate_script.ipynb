{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import multirecording_spikeanalysis as spike\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ephys Recording Object: Phase 2 (Freely moving)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each recording is an ephysrecording instance; the documentation is as follows: \n",
    "\n",
    "A class for an ephys recording after being spike sorted and manually\n",
    "curated using phy. Ephys recording must have a phy folder.\n",
    "\n",
    "\n",
    "    Attributes:\n",
    "        path: str, relative path to the phy folder\n",
    "            formatted as: './folder/folder/phy'\n",
    "        subject: str, subject id who was being recorded\n",
    "        event_dict: dict, start and stop times for events\n",
    "            keys: str, name of event types\n",
    "            values: np.array, d =(n,2), each 2D array is the start and stop time \n",
    "            in ms for each event, n = number of events of type key\n",
    "        sampling_rate: int, sampling rate of the ephys device\n",
    "            in Hz, standard in the PC lab is 20,000Hz\n",
    "        timestamps_var: numpy array, all spike timestamps\n",
    "            of good and mua units (no noise unit-generated spikes)\n",
    "        unit_array: numpy array, unit ids associated with each\n",
    "            spike in the timestamps_var\n",
    "        labels_dict: dict, keys are unit ids (str) and\n",
    "            values are labels (str)\n",
    "        unit_timestamps: dict, keys are unit ids (int), and\n",
    "            values are numpy arrays of timestamps for all spikes\n",
    "            from \"good\" units only\n",
    "        spiketrain: np.array, spiketrain of number of spikes\n",
    "            in a specified timebin\n",
    "        unit_spiketrains: dict, spiketrains for each unit\n",
    "            keys: str, unit ids\n",
    "            values: np.array, number of spikes per specified timebin\n",
    "        unit_firing_rates: dict, firing rates per unit\n",
    "            keys: str, unit ids\n",
    "            values: np.arrays, firing rate of unit in a specified timebin\n",
    "                    calculated with a specified smoothing window\n",
    "\n",
    "    Methods: (all called in __init__)\n",
    "        get_unit_labels: creates labels_dict\n",
    "        get_spike_specs: creates timestamps_var and unit_array\n",
    "        get_unit_timestamps: creates unit_timestamps dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All recordings have been put into an instance of the class type ephysrecordingcollection.\n",
    "Big picture is that phase2_collection has an attribute called collection which is a dictionary of \n",
    "recording names: recording objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2_collection = unpickle_this('phase2_collection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example recording:\n",
      "20230803_101331_1_merged.rec\n",
      "\n",
      "Event Types:\n",
      "dict_keys(['acquisition', 'recall', 'cagemate', 'novel', 'exposure 1', 'exposure 2', 'exposure 3'])\n",
      "\n",
      "Number of units:\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "is_first = True\n",
    "for recording_name, recording in phase2_collection.collection.items():\n",
    "    if is_first:\n",
    "        print('Example recording:')\n",
    "        print(recording_name)\n",
    "        print(\"\")\n",
    "        print('Event Types:')\n",
    "        print(recording.event_dict.keys())\n",
    "        print(\"\")\n",
    "        print('Number of units:')\n",
    "        print(len(recording.unit_timestamps.keys()))\n",
    "        is_first = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Analysis Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another class I made for spike analysis specifically. \n",
    "\n",
    "Parameters that you should feel free to play with are smoothin_window and timebin (both in ms).\n",
    "\n",
    "    Timebin:\n",
    "        window for each element in all the arrays (spiketrains, firing rates, etc.).\n",
    "    Smoothing window:\n",
    "        the rolling average window size to be used when calculating firing rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set to analyze\n"
     ]
    }
   ],
   "source": [
    "phase2_analysis = spike.SpikeAnalysis_MultiRecording(\n",
    "    phase2_collection,\n",
    "    smoothing_window = 250,\n",
    "    timebin = 100,\n",
    "    ignore_freq = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_firing_rates = {}\n",
    "#event type\n",
    "event = 'acquisition'\n",
    "#event length (in seconds)\n",
    "equalize = 5\n",
    "#time prior to event start to be included (in seconds)\n",
    "pre_window = 0\n",
    "\n",
    "\n",
    "#will calculate unit firing rates during specified event type for specified length of time\n",
    "#and save them into a dictionary \n",
    "for recording_name, recording in phase2_collection.collection.items():     \n",
    "    event_firing_rates[recording] = phase2_analysis.__get_unit_event_firing_rates__(\n",
    "            recording,\n",
    "            event,\n",
    "            equalize,\n",
    "            pre_window\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Constrained \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase3_collection = unpickle_this('phase3_collection.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example recording:\n",
      "20230809_103121_1_merged.rec\n",
      "\n",
      "Event Types:\n",
      "dict_keys(['acquisition', 'cagemate', 'empty', 'novel', 'familiar'])\n",
      "\n",
      "Number of units:\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "is_first = True\n",
    "for recording_name, recording in phase3_collection.collection.items():\n",
    "    if is_first:\n",
    "        print('Example recording:')\n",
    "        print(recording_name)\n",
    "        print(\"\")\n",
    "        print('Event Types:')\n",
    "        print(recording.event_dict.keys())\n",
    "        print(\"\")\n",
    "        print('Number of units:')\n",
    "        print(len(recording.unit_timestamps.keys()))\n",
    "        is_first = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
