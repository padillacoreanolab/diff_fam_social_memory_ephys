{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\megha\\Documents\\GitHub\\diff_fam_social_memory_ephys\\lfp\\lfp_analysis\n"
     ]
    }
   ],
   "source": [
    "%cd lfp_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LFP_collection\n",
    "import lfp_analysis\n",
    "import pickle\n",
    "def hex_2_rgb(hex_color): # Orange color\n",
    "    rgb_color = tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (1, 3, 5))\n",
    "    return rgb_color\n",
    "\n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):   \n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):   \n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'LFP_collection' from 'c:\\\\Users\\\\megha\\\\Documents\\\\GitHub\\\\diff_fam_social_memory_ephys\\\\lfp\\\\lfp_analysis\\\\LFP_collection.py'>\n"
     ]
    }
   ],
   "source": [
    "print(LFP_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Padilla-Coreano\\\\UFL Dropbox\\\\Caroline De Paula Cunha Almeida\\\\Padilla-Coreano Lab\\\\2024\\\\Cum_SocialMemEphys_pilot2\\\\Habituation_Dishabituation (phase 1)\\\\data\\\\novel\\\\13_nov_p1.rec\\\\13_nov_p1_merged.rec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m novel_lfp \u001b[38;5;241m=\u001b[39m \u001b[43munpickle_this\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmegha\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUFL Dropbox\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMeghan Cum\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPadilla-Coreano Lab\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2024\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCum_SocialMemEphys_pilot2\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mprocessed_lfp_pickles\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mnovel_p1_processed_lfp.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m cage_lfp \u001b[38;5;241m=\u001b[39m unpickle_this(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmegha\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUFL Dropbox\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMeghan Cum\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPadilla-Coreano Lab\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2024\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCum_SocialMemEphys_pilot2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprocessed_lfp_pickles\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcagemate_p1_processed_lfp.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[21], line 29\u001b[0m, in \u001b[0;36munpickle_this\u001b[1;34m(pickle_file)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03mUnpickles things\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03mArgs (1):   \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    pickled item\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pickle_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\spikeinterface\\core\\base.py:502\u001b[0m, in \u001b[0;36mBaseExtractor.from_dict\u001b[1;34m(dictionary, base_folder)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m base_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen  relative_paths=True, need to provide base_folder\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    501\u001b[0m     dictionary \u001b[38;5;241m=\u001b[39m make_paths_absolute(dictionary, base_folder)\n\u001b[1;32m--> 502\u001b[0m extractor \u001b[38;5;241m=\u001b[39m \u001b[43m_load_extractor_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m folder_metadata \u001b[38;5;241m=\u001b[39m dictionary\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfolder_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m folder_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\spikeinterface\\core\\base.py:1085\u001b[0m, in \u001b[0;36m_load_extractor_from_dict\u001b[1;34m(dic)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersions are not the same. This might lead to compatibility errors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1081\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdic[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is recommended\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1082\u001b[0m     )\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;66;03m# Initialize the extractor\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m extractor \u001b[38;5;241m=\u001b[39m extractor_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_kwargs)\n\u001b[0;32m   1087\u001b[0m extractor\u001b[38;5;241m.\u001b[39m_annotations\u001b[38;5;241m.\u001b[39mupdate(dic[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m dic[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproperties\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\spikegadgets.py:34\u001b[0m, in \u001b[0;36mSpikeGadgetsRecordingExtractor.__init__\u001b[1;34m(self, file_path, stream_id, stream_name, block_index, all_annotations)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path, stream_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, stream_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, block_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, all_annotations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     33\u001b[0m     neo_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap_to_neo_kwargs(file_path)\n\u001b[1;32m---> 34\u001b[0m     NeoBaseRecordingExtractor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;28mself\u001b[39m, stream_id\u001b[38;5;241m=\u001b[39mstream_id, stream_name\u001b[38;5;241m=\u001b[39mstream_name, all_annotations\u001b[38;5;241m=\u001b[39mall_annotations, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs\n\u001b[0;32m     36\u001b[0m     )\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(file_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(Path(file_path)\u001b[38;5;241m.\u001b[39mabsolute()), stream_id\u001b[38;5;241m=\u001b[39mstream_id))\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:187\u001b[0m, in \u001b[0;36mNeoBaseRecordingExtractor.__init__\u001b[1;34m(self, stream_id, stream_name, block_index, all_annotations, use_names_as_ids, **neo_kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    160\u001b[0m     stream_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    167\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    Initialize a NeoBaseRecordingExtractor instance.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 187\u001b[0m     _NeoBaseExtractor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, block_index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs)\n\u001b[0;32m    189\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(all_annotations\u001b[38;5;241m=\u001b[39mall_annotations)\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m block_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:27\u001b[0m, in \u001b[0;36m_NeoBaseExtractor.__init__\u001b[1;34m(self, block_index, **neo_kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, block_index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs):\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Avoids double initiation of the neo reader if it was already done in the __init__ of the child class\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneo_reader\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneo_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_neo_io_reader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNeoRawIOClass, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneo_reader\u001b[38;5;241m.\u001b[39mblock_count() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis dataset is multi-block. Spikeinterface can load one block at a time. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock_index\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to select the block to be loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\spikeinterface\\extractors\\neoextractors\\neobaseextractor.py:66\u001b[0m, in \u001b[0;36m_NeoBaseExtractor.get_neo_io_reader\u001b[1;34m(cls, raw_class, **neo_kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m neoIOclass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(rawio_module, raw_class)\n\u001b[0;32m     65\u001b[0m neo_reader \u001b[38;5;241m=\u001b[39m neoIOclass(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo_kwargs)\n\u001b[1;32m---> 66\u001b[0m \u001b[43mneo_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m neo_reader\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\neo\\rawio\\baserawio.py:199\u001b[0m, in \u001b[0;36mBaseRawIO.parse_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03mParses the header of the file(s) to allow for faster computations\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03mfor all other functions\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# this must create\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# self.header['nb_block']\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# self.header['nb_segment']\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# self.header['spike_channels']\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# self.header['event_channels']\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_stream_signal_channel_characteristics()\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_header_parsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\megha\\anaconda3\\envs\\lfp_env\\lib\\site-packages\\neo\\rawio\\spikegadgetsrawio.py:109\u001b[0m, in \u001b[0;36mSpikeGadgetsRawIO._parse_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# parse file until \"</Configuration>\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     header_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    111\u001b[0m             line \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadline()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Padilla-Coreano\\\\UFL Dropbox\\\\Caroline De Paula Cunha Almeida\\\\Padilla-Coreano Lab\\\\2024\\\\Cum_SocialMemEphys_pilot2\\\\Habituation_Dishabituation (phase 1)\\\\data\\\\novel\\\\13_nov_p1.rec\\\\13_nov_p1_merged.rec'"
     ]
    }
   ],
   "source": [
    "novel_lfp = unpickle_this(r\"C:\\Users\\megha\\UFL Dropbox\\Meghan Cum\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\processed_lfp_pickles\\novel_p1_processed_lfp.pkl\")\n",
    "cage_lfp = unpickle_this(r\"C:\\Users\\megha\\UFL Dropbox\\Meghan Cum\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\processed_lfp_pickles\\cagemate_p1_processed_lfp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
