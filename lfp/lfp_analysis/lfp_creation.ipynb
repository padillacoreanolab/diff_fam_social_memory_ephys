{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPECTRAL_CONNECTIVITY_ENABLE_GPU=true\n"
     ]
    }
   ],
   "source": [
    "%env SPECTRAL_CONNECTIVITY_ENABLE_GPU=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../lfp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRYING GPU!\n",
      "THIS IS GPU\n",
      "c:\\Users\\Padilla-Coreano\\.conda\\envs\\ephy_analysis\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "c:\\Users\\Padilla-Coreano\\.conda\\envs\\ephy_analysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cupy as xp\n",
    "from cupyx.scipy.fft import ifft\n",
    "from cupyx.scipy.sparse.linalg import svds\n",
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "import LFP_recording as LFP_recording\n",
    "import LFP_collection as LFP_collection\n",
    "import preprocessor as preprocessor\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import os\n",
    "from bidict import bidict\n",
    "import pickle\n",
    "\n",
    "def hex_2_rgb(hex_color): # Orange color\n",
    "    rgb_color = tuple(int(hex_color[i:i+2], 16) / 255.0 for i in (1, 3, 5))\n",
    "    return rgb_color\n",
    "\n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):   \n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl \n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name,'wb') as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):   \n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, 'rb') as file:\n",
    "        return(pickle.load(file))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'22_object_merged.rec': '2.2', '44_object_merged.rec': '4.4', '23_object_merged.rec': '2.3', '41_object_merged.rec': '4.1', '31_object_merged.rec': '3.1', '32_object_merged.rec': '3.2'}\n",
      "Processing 22_object_merged.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Padilla-Coreano\\Desktop\\GITHUB_REPOS\\diff_fam_social_memory_ephys\\lfp\\lfp_analysis\\../../lfp\\trodes\\read_exported.py:167: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  return np.dtype(dtype_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted first timestamp\n",
      "Processing 44_object_merged.rec\n",
      "Extracted first timestamp\n",
      "Processing 23_object_merged.rec\n",
      "Extracted first timestamp\n",
      "Processing 41_object_merged.rec\n",
      "Extracted first timestamp\n",
      "Processing 31_object_merged.rec\n",
      "Extracted first timestamp\n",
      "Processing 32_object_merged.rec\n",
      "Extracted first timestamp\n"
     ]
    }
   ],
   "source": [
    "trodes_directory = r'C:\\Users\\Padilla-Coreano\\Desktop\\Trodes_2-5-3_Windows64'\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\Padilla-Coreano\\Desktop\\GITHUB_REPOS\\diff_fam_social_memory_ephys\\lfp\\channel_mapping_sme.xlsx\")\n",
    "spike_cols = [col for col in df.columns if 'spike_interface_' in col.lower()]\n",
    "\n",
    "# Extract brain regions from column names\n",
    "# Assumes format 'spike_interface_REGION'\n",
    "brain_regions = [col.split('spike_interface_')[1] for col in spike_cols]\n",
    "\n",
    "# Create nested dictionary\n",
    "subject_to_channel_dict = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    subject = row['Subject'].astype(str)\n",
    "    # Initialize inner dictionary for this subject\n",
    "    subject_to_channel_dict[subject] = {}\n",
    "    \n",
    "    # Populate inner dictionary with brain region: spike value pairs\n",
    "    for col, region in zip(spike_cols, brain_regions):\n",
    "        subject_to_channel_dict[subject][region] = int(row[col])\n",
    "behavior_dicts = {}\n",
    "def make_recording_to_subj_dict(data_path):\n",
    "    recording_to_subject = {}\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            if file.endswith('merged.rec'):\n",
    "                subject = str(int((file.split(\"_\")[0]))/10)\n",
    "                recording_to_subject[file] = subject\n",
    "                behavior_dicts[file] = {}\n",
    "    return recording_to_subject\n",
    "\n",
    "\n",
    "def process(data_path):\n",
    "    recording_to_subject = make_recording_to_subj_dict(data_path)\n",
    "    print(recording_to_subject)\n",
    "    collection = LFP_collection.LFPCollection(behavior_dicts, subject_to_channel_dict, data_path, recording_to_subject, 4, trodes_directory)\n",
    "    #collection.process()\n",
    "    return collection\n",
    "    \n",
    "    \n",
    "data_path = r\"C:\\Users\\Padilla-Coreano\\UFL Dropbox\\Caroline De Paula Cunha Almeida\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\Object_Control (phase 8)\\data\"\n",
    "pickle_path = r\"C:\\Users\\Padilla-Coreano\\UFL Dropbox\\Caroline De Paula Cunha Almeida\\Padilla-Coreano Lab\\2024\\Cum_SocialMemEphys_pilot2\\processed_lfp_pickles\\object_control_p8_processed_lfp.pkl\"\n",
    "collection = process(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 22_object_merged.rec\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 2852 of 3620 converged\n",
      "Maximum iterations reached. 2984 of 3620 converged\n",
      "Maximum iterations reached. 2779 of 3620 converged\n",
      "Maximum iterations reached. 2768 of 3620 converged\n",
      "Maximum iterations reached. 2816 of 3620 converged\n",
      "Maximum iterations reached. 2711 of 3620 converged\n",
      "Maximum iterations reached. 2576 of 3620 converged\n",
      "Maximum iterations reached. 2785 of 3620 converged\n",
      "Maximum iterations reached. 2794 of 3620 converged\n",
      "Maximum iterations reached. 2546 of 3620 converged\n",
      " 17%|█▋        | 1/6 [05:03<25:16, 303.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 44_object_merged.rec\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3252 of 3618 converged\n",
      "Maximum iterations reached. 3312 of 3618 converged\n",
      "Maximum iterations reached. 3182 of 3618 converged\n",
      "Maximum iterations reached. 3036 of 3618 converged\n",
      "Maximum iterations reached. 3331 of 3618 converged\n",
      "Maximum iterations reached. 3215 of 3618 converged\n",
      "Maximum iterations reached. 3040 of 3618 converged\n",
      "Maximum iterations reached. 3331 of 3618 converged\n",
      "Maximum iterations reached. 3227 of 3618 converged\n",
      "Maximum iterations reached. 3048 of 3618 converged\n",
      " 33%|███▎      | 2/6 [10:05<20:10, 302.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 23_object_merged.rec\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3447 of 3660 converged\n",
      "Maximum iterations reached. 3499 of 3660 converged\n",
      "Maximum iterations reached. 3365 of 3660 converged\n",
      "Maximum iterations reached. 2900 of 3660 converged\n",
      "Maximum iterations reached. 3507 of 3660 converged\n",
      "Maximum iterations reached. 3420 of 3660 converged\n",
      "Maximum iterations reached. 2937 of 3660 converged\n",
      "Maximum iterations reached. 3466 of 3660 converged\n",
      "Maximum iterations reached. 3026 of 3660 converged\n",
      "Maximum iterations reached. 2891 of 3660 converged\n",
      " 50%|█████     | 3/6 [15:21<15:26, 308.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 41_object_merged.rec\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3324 of 3659 converged\n",
      "Maximum iterations reached. 3460 of 3659 converged\n",
      "Maximum iterations reached. 3287 of 3659 converged\n",
      "Maximum iterations reached. 2314 of 3659 converged\n",
      "Maximum iterations reached. 3324 of 3659 converged\n",
      "Maximum iterations reached. 3197 of 3659 converged\n",
      "Maximum iterations reached. 2222 of 3659 converged\n",
      "Maximum iterations reached. 3331 of 3659 converged\n",
      "Maximum iterations reached. 2340 of 3659 converged\n",
      "Maximum iterations reached. 2224 of 3659 converged\n",
      " 67%|██████▋   | 4/6 [20:37<10:23, 311.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 31_object_merged.rec\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 3354 of 3659 converged\n",
      "Maximum iterations reached. 2933 of 3659 converged\n",
      "Maximum iterations reached. 3211 of 3659 converged\n",
      "Maximum iterations reached. 3033 of 3659 converged\n",
      "Maximum iterations reached. 2983 of 3659 converged\n",
      "Maximum iterations reached. 3282 of 3659 converged\n",
      "Maximum iterations reached. 3026 of 3659 converged\n",
      "Maximum iterations reached. 2859 of 3659 converged\n",
      "Maximum iterations reached. 2577 of 3659 converged\n",
      "Maximum iterations reached. 2889 of 3659 converged\n",
      " 83%|████████▎ | 5/6 [26:07<05:18, 318.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n",
      "processing 32_object_merged.rec\n",
      "RMS Traces calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 2777 of 3660 converged\n",
      "Maximum iterations reached. 2749 of 3660 converged\n",
      "Maximum iterations reached. 2713 of 3660 converged\n",
      "Maximum iterations reached. 2655 of 3660 converged\n",
      "Maximum iterations reached. 2671 of 3660 converged\n",
      "Maximum iterations reached. 2629 of 3660 converged\n",
      "Maximum iterations reached. 2444 of 3660 converged\n",
      "Maximum iterations reached. 2589 of 3660 converged\n",
      "Maximum iterations reached. 2350 of 3660 converged\n",
      "Maximum iterations reached. 2396 of 3660 converged\n",
      "100%|██████████| 6/6 [31:41<00:00, 316.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger's causality calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collection.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_this(collection, pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephy_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
