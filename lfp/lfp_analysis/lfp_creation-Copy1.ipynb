{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SPECTRAL_CONNECTIVITY_ENABLE_GPU=true\n"
     ]
    }
   ],
   "source": [
    "%env SPECTRAL_CONNECTIVITY_ENABLE_GPU=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/npadillacoreano/mcum/conda/envs/lfp_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys')\n",
    "\n",
    "\n",
    "import cupy as xp\n",
    "from cupyx.scipy.fft import ifft\n",
    "from cupyx.scipy.sparse.linalg import svds\n",
    "from spectral_connectivity import Multitaper, Connectivity\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import os\n",
    "from bidict import bidict\n",
    "import lfp.lfp_analysis.LFP_collection as LFP_collection\n",
    "import pickle \n",
    "def pickle_this(thing_to_pickle, file_name):\n",
    "    \"\"\"\n",
    "    Pickles things\n",
    "    Args (2):\n",
    "        thing_to_pickle: anything you want to pickle\n",
    "        file_name: str, filename that ends with .pkl\n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        pickle.dump(thing_to_pickle, file)\n",
    "def unpickle_this(pickle_file):\n",
    "    \"\"\"\n",
    "    Unpickles things\n",
    "    Args (1):\n",
    "        file_name: str, pickle filename that already exists and ends with .pkl\n",
    "    Returns:\n",
    "        pickled item\n",
    "    \"\"\"\n",
    "    with open(pickle_file, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "os.chdir('/blue/npadillacoreano')\n",
    "df = pd.read_excel(r\"share/reward_comp_extention/rce_channel_mapping.xlsx\")\n",
    "spike_cols = [col for col in df.columns if 'spike_interface_' in col.lower()]\n",
    "\n",
    "# Extract brain regions from column names\n",
    "# Assumes format 'spike_interface_REGION'\n",
    "brain_regions = [col.split('spike_interface_')[1] for col in spike_cols]\n",
    "\n",
    "# Create nested dictionary\n",
    "subject_to_channel_dict = {}\n",
    "\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    subject = str(row['Subject'])\n",
    "    # Initialize inner dictionary for this subject\n",
    "    subject_to_channel_dict[subject] = {}\n",
    "    \n",
    "    # Populate inner dictionary with brain region: spike value pairs\n",
    "    for col, region in zip(spike_cols, brain_regions):\n",
    "        subject_to_channel_dict[subject][region] = int(row[col])\n",
    "behavior_dicts = {}\n",
    "#pickle_this(subject_to_channel_dict[\n",
    "\n",
    "def make_recording_to_subj_dict(data_path):\n",
    "    recording_to_subject = {}\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for file in files:\n",
    "            if file.endswith('merged.rec'):\n",
    "                if file.startswith('2023'):\n",
    "                    subject = str(file.split(\"_\")[-4].replace('-','.'))\n",
    "                    recording_to_subject[file] = subject\n",
    "                    behavior_dicts[file] = {}\n",
    "                if file.startswith('2024'):\n",
    "                    subject = str(file.split(\"_\")[-3].replace('-','.'))\n",
    "                    recording_to_subject[file] = subject\n",
    "                    behavior_dicts[file] = {}   \n",
    "                if (file == '20230620_114347_standard_comp_to_omission_D4_subj_1-1_t1b2L_box_2_merged.rec')| (file == '20230620_114347_standard_comp_to_omission_D4_subj_1-2_t3b3L_box_1_merged.rec'):\n",
    "                    subject = str(file.split(\"_\")[-5].replace('-','.'))\n",
    "                    recording_to_subject[file] = subject\n",
    "                    behavior_dicts[file] = {}\n",
    "                if file =='20230618_100636_standard_comp_to_omission_D2_subj_1_1_t1b2L_box2_merged.rec':\n",
    "                    recording_to_subject[file] = '1.1'\n",
    "                if file == '20230618_100636_standard_comp_to_omission_D2_subj_1_4_t4b3L_box1_merged.rec':\n",
    "                    recording_to_subject[file] = '1.4'\n",
    "                \n",
    "    return recording_to_subject\n",
    "\n",
    "# def process(data_path):\n",
    "#     recording_to_subject = make_recording_to_subj_dict(data_path)\n",
    "#     print(recording_to_subject)\n",
    "#     collection = LFP_collection.LFPCollection(subject_to_channel_dict, data_path, recording_to_subject, 4)\n",
    "#     #collection.process()\n",
    "#     return collection    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['20230612_101430_standard_comp_to_training_D1_subj_1-4_t4b2L_box1_merged.rec', '20230612_101430_standard_comp_to_training_D1_subj_1-3_t3b3L_box2_merged.rec', '20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.rec', '20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.rec', '20230613_105657_standard_comp_to_training_D2_subj_1-1_t1b2L_box1_merged.rec', '20230613_105657_standard_comp_to_training_D2_subj_1-4_t4b3L_box2_merged.rec', '20230614_114041_standard_comp_to_training_D3_subj_1-1_t1b3L_box1_merged.rec', '20230614_114041_standard_comp_to_training_D3_subj_1-2_t2b2L_box2_merged.rec', '20230616_111904_standard_comp_to_training_D4_subj_1-4_t4b3L_box1_merged.rec', '20230616_111904_standard_comp_to_training_D4_subj_1-2_t2b2L_box2_merged.rec', '20230617_115521_standard_comp_to_omission_D1_subj_1-1_t1b3L_box1_merged.rec', '20230617_115521_standard_comp_to_omission_D1_subj_1-2_t2b2L_box2_merged.rec', '20230618_100636_standard_comp_to_omission_D2_subj_1-4_t4b3L_box1_merged.rec', '20230618_100636_standard_comp_to_omission_D2_subj_1-1_t1b2L_box2_merged.rec', '20230619_115321_standard_comp_to_omission_D3_subj_1-4_t3b3L_box2_merged.rec', '20230620_114347_standard_comp_to_omission_D4_subj_1-2_t3b3L_box_1_merged.rec', '20230620_114347_standard_comp_to_omission_D4_subj_1-1_t1b2L_box_2_merged.rec', '20230621_111240_standard_comp_to_omission_D5_subj_1-4_t3b3L_box1_merged.rec', '20240320_142408_alone_comp_subj_3-1_t6b6_merged.rec', '20240320_142408_alone_comp_subj_3-3_t5b5_merged.rec', '20240320_171038_alone_comp_subj_4-2_t6b6_merged.rec', '20240320_171038_alone_comp_subj_4-3_t5b5_merged.rec', '20240322_120625_alone_comp_subj_3-3_t6b6_merged.rec', '20240322_120625_alone_comp_subj_3-4_t5b5_merged.rec', '20240322_160946_alone_comp_subj_4-3_t6b6_merged.rec', '20240322_160946_alone_comp_subj_4-4_t5b5_merged.rec', '20240323_122227_alone_comp_subj_5-2_t6b6_merged.rec', '20240323_122227_alone_comp_subj_5-3_t5b5_merged.rec', '20240323_144517_alone_comp_subj_3-1_t5b5_merged.rec', '20240323_144517_alone_comp_subj_3-4_t6b6_merged.rec', '20240323_165815_alone_comp_subj_4-2_t5b5_merged.rec', '20240323_165815_alone_comp_subj_4-4_t6b6_merged.rec', '20240317_151922_long_comp_subj_3-1_t6b6_merged.rec', '20240317_151922_long_comp_subj_3-3_t5b5_merged.rec', '20240317_172017_long_comp_subj_4-2_t6b6_merged.rec', '20240317_172017_long_comp_subj_4-3_t5b5_merged.rec', '20240318_143819_long_comp_subj_3-3_t6b6_merged.rec', '20240318_143819_long_comp_subj_3-4_t5b5_merged.rec', '20240318_170933_long_comp_subj_4-3_t6b6_merged.rec', '20240318_170933_long_comp_subj_4-4_t5b5_merged.rec', '20240319_160457_long_comp_subj_4-2_t5b5_merged.rec', '20240319_160457_long_comp_subj_4-4_t6b6_merged.rec', '20240320_114629_long_comp_subj_5-3_t6b6_merged.rec', '20240320_114629_long_comp_subj_5-4_t5b5_merged.rec', '20240321_114851_long_comp_subj_5-2_t6b6_merged.rec', '20240321_114851_long_comp_subj_5-3_t5b5_merged.rec'])\n"
     ]
    }
   ],
   "source": [
    "event_dict_meg = unpickle_this(r\"share/reward_comp_extention/event_dict_meg.pkl\")\n",
    "event_dict = unpickle_this(r\"share/reward_comp_extention/event_dict.pkl\")\n",
    "\n",
    "print(event_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = r\"share/reward_comp_extention/LFP_rce2_rce3/megadataset/batch2\"\n",
    "recording_to_subject = make_recording_to_subj_dict(data_path)\n",
    "recordings = list(event_dict.keys())\n",
    "for key in recording_to_subject.keys():\n",
    "    if key not in recordings:\n",
    "        print(key)\n",
    "#5.3 v 5.5 only have one comp in long comp\n",
    "#3.1 v 3.4 only have one in alone comp - no long comp since the wrong mice were but in \n",
    "\n",
    "# long_comp = 0\n",
    "# alone_comp= 0\n",
    "# training = 0\n",
    "# omission = 0\n",
    "# for key in recording_to_subject.keys():\n",
    "#     if 'alone' in key:\n",
    "#         alone_comp += 1\n",
    "#     if 'long' in key:\n",
    "#         long_comp += 1\n",
    "#     if 'training' in key:\n",
    "#         training += 1\n",
    "#     if 'omission' in key:\n",
    "#         omission += 1\n",
    "#         print(key)\n",
    "# print('long comp', long_comp)\n",
    "# print('alone comp', alone_comp)\n",
    "# print('training', training)\n",
    "# print('omission', omission)\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.rec\n",
      "Found first timestamp\n",
      "Processing 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.rec\n",
      "Found first timestamp\n",
      "Processing 20230612_101430_standard_comp_to_training_D1_subj_1-4_t4b2L_box1_merged.rec\n",
      "Found first timestamp\n",
      "Processing 20230612_101430_standard_comp_to_training_D1_subj_1-3_t3b3L_box2_merged.rec\n",
      "Found first timestamp\n",
      "Processing 20230613_105657_standard_comp_to_training_D2_subj_1-1_t1b2L_box1_merged.rec\n",
      "Found first timestamp\n",
      "Processing 20230613_105657_standard_comp_to_training_D2_subj_1-4_t4b3L_box2_merged.rec\n",
      "Found first timestamp\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('/blue/npadillacoreano/mcum/SocialMemEphys/diff_fam_social_memory_ephys')\n",
    "\n",
    "collection = LFP_collection.LFPCollection(subject_to_channel_dict, data_path, recording_to_subject, 5, recording_to_event_dict=event_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 20230612_112630_standard_comp_to_training_D1_subj_1-2_t2b2L_box1_merged.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:00<00:03,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Traces calculated\n",
      "processing 20230612_112630_standard_comp_to_training_D1_subj_1-1_t1b3L_box2_merged.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:01<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Traces calculated\n",
      "processing 20230612_101430_standard_comp_to_training_D1_subj_1-4_t4b2L_box1_merged.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:02<00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Traces calculated\n",
      "processing 20230612_101430_standard_comp_to_training_D1_subj_1-3_t3b3L_box2_merged.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:02<00:01,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Traces calculated\n",
      "processing 20230613_105657_standard_comp_to_training_D2_subj_1-1_t1b2L_box1_merged.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:03<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Traces calculated\n",
      "processing 20230613_105657_standard_comp_to_training_D2_subj_1-4_t4b3L_box2_merged.rec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:04<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Traces calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 6752 of 6833 converged\n",
      "Maximum iterations reached. 6717 of 6833 converged\n",
      "Maximum iterations reached. 6746 of 6833 converged\n",
      "Maximum iterations reached. 6344 of 6833 converged\n",
      "Maximum iterations reached. 6698 of 6833 converged\n",
      "Maximum iterations reached. 6755 of 6833 converged\n",
      "Maximum iterations reached. 6354 of 6833 converged\n",
      "Maximum iterations reached. 6717 of 6833 converged\n",
      "Maximum iterations reached. 6316 of 6833 converged\n",
      "Maximum iterations reached. 6348 of 6833 converged\n",
      " 17%|█▋        | 1/6 [00:56<04:44, 56.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 6793 of 6833 converged\n",
      "Maximum iterations reached. 6792 of 6833 converged\n",
      "Maximum iterations reached. 6808 of 6833 converged\n",
      "Maximum iterations reached. 6709 of 6833 converged\n",
      "Maximum iterations reached. 6770 of 6833 converged\n",
      "Maximum iterations reached. 6807 of 6833 converged\n",
      "Maximum iterations reached. 6712 of 6833 converged\n",
      "Maximum iterations reached. 6802 of 6833 converged\n",
      "Maximum iterations reached. 6708 of 6833 converged\n",
      "Maximum iterations reached. 6716 of 6833 converged\n",
      " 33%|███▎      | 2/6 [01:42<03:21, 50.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 6040 of 6828 converged\n",
      "Maximum iterations reached. 6027 of 6828 converged\n",
      "Maximum iterations reached. 6398 of 6828 converged\n",
      "Maximum iterations reached. 6401 of 6828 converged\n",
      "Maximum iterations reached. 6046 of 6828 converged\n",
      "Maximum iterations reached. 6083 of 6828 converged\n",
      "Maximum iterations reached. 6136 of 6828 converged\n",
      "Maximum iterations reached. 6067 of 6828 converged\n",
      "Maximum iterations reached. 6117 of 6828 converged\n",
      "Maximum iterations reached. 6485 of 6828 converged\n",
      " 50%|█████     | 3/6 [02:28<02:24, 48.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 6159 of 6828 converged\n",
      "Maximum iterations reached. 6131 of 6828 converged\n",
      "Maximum iterations reached. 6140 of 6828 converged\n",
      "Maximum iterations reached. 6001 of 6828 converged\n",
      "Maximum iterations reached. 6170 of 6828 converged\n",
      "Maximum iterations reached. 6268 of 6828 converged\n",
      "Maximum iterations reached. 6061 of 6828 converged\n",
      "Maximum iterations reached. 6291 of 6828 converged\n",
      "Maximum iterations reached. 6025 of 6828 converged\n",
      "Maximum iterations reached. 6029 of 6828 converged\n",
      " 67%|██████▋   | 4/6 [03:14<01:34, 47.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 6812 of 6840 converged\n",
      "Maximum iterations reached. 6814 of 6840 converged\n",
      "Maximum iterations reached. 6830 of 6840 converged\n",
      "Maximum iterations reached. 6738 of 6840 converged\n",
      "Maximum iterations reached. 6802 of 6840 converged\n",
      "Maximum iterations reached. 6823 of 6840 converged\n",
      "Maximum iterations reached. 6738 of 6840 converged\n",
      "Maximum iterations reached. 6828 of 6840 converged\n",
      "Maximum iterations reached. 6736 of 6840 converged\n",
      "Maximum iterations reached. 6738 of 6840 converged\n",
      " 83%|████████▎ | 5/6 [04:00<00:46, 46.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality calculated\n",
      "Power Calculated\n",
      "Coherence calcualatd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum iterations reached. 6605 of 6841 converged\n",
      "Maximum iterations reached. 6603 of 6841 converged\n",
      "Maximum iterations reached. 6587 of 6841 converged\n",
      "Maximum iterations reached. 6617 of 6841 converged\n",
      "Maximum iterations reached. 6747 of 6841 converged\n",
      "Maximum iterations reached. 6753 of 6841 converged\n",
      "Maximum iterations reached. 6784 of 6841 converged\n",
      "Maximum iterations reached. 6747 of 6841 converged\n",
      "Maximum iterations reached. 6779 of 6841 converged\n",
      "Maximum iterations reached. 6781 of 6841 converged\n",
      "100%|██████████| 6/6 [04:46<00:00, 47.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "collection.preprocess(threshold = 5)\n",
    "collection.calculate_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# collection.save_to_json(r\"share/reward_comp_extention/LFP_rce2_rce3/megadataset/lfp_batch1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.save_to_json(r\"share/reward_comp_extention/LFP_rce2_rce3/megadataset/lfp_batch2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfp_env",
   "language": "python",
   "name": "lfp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
